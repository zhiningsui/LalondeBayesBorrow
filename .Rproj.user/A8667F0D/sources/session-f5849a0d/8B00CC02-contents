library(kableExtra)
library(ggplot2)
library(reshape2)
library(patchwork)

source("functions_Bayesian_Lalonde_7_26.R")

# #  Run Simulations - g-score ----------------------------------------------
# 
# ## Define the range of values for each parameter
# # 7/8/2024
# param_grid <- expand.grid(
#   trt_n = seq(15,40, 5), # Sample size for the treatment group.
#   ctrl_n = seq(15,40, 5), # Sample size for the control group.
#   # trt_h_n = 200, # Sample size for the historical treatment group.
#   ctrl_h_n = 200, # Sample size for the historical control group.
#   trt_prob = 0.1, # Probability of zero g-scores in the treatment group.
#   ctrl_prob = c(0.1, 0.15), # Probability of zero g-scores in the control group.
#   # trt_h_prob = 0.1, # Probability of zero g-scores in the historical treatment group.
#   ctrl_h_prob = 0.1, # Probability of zero g-scores in the historical control group.
#   trt_mu = c(0.004, 0.005, 0.006, 0.007, 0.008, 0.009), # Mean for the non-zero g-scores in the treatment group.
#   ctrl_mu = 0.01, # Mean for the non-zero g-scores in the control group.
#   # trt_h_mu = c(0.004, 0.005, 0.006, 0.007, 0.008, 0.009), # Mean for the non-zero g-scores in the historical treatment group.
#   ctrl_h_mu = c(0.01/0.7, 0.01/0.85, 0.01/0.9, 0.01, 0.01*0.9, 0.01*0.85, 0.01*0.7), # Mean for the non-zero g-scores in the historical control group.
#   trt_sigma = 1, # Standard deviation for the non-zero g-scores in the treatment group.
#   ctrl_sigma = 1, # Standard deviation for the non-zero g-scores in the control group.
#   # trt_h_sigma = 1, # Standard deviation for the non-zero g-scores in the historical treatment group.
#   ctrl_h_sigma = 1, # Standard deviation for the non-zero g-scores in the historical control group.
#   stringsAsFactors = FALSE
# ) %>%
#   filter(trt_n == ctrl_n)
# 
# ## Create a list of parameters used for data generation.
# # Note that the mu's are taken logarithm since non-zero g-score follows log-normal(mu, sigma)
# data_gen_params_list <- lapply(apply(param_grid, 1, as.list),
#                                create_data_gen_params, endpoint = "g-score")
# 
# ## Create a list of prior parameters
# # delta: Clinically significant difference (CSD) in treatment effect, as the threshold for prior-data conflict.
# #        H_0: log(ctrl_mu) = log(ctrl_h_mu) vs H_1: |log(ctrl_h_mu) - log(ctrl_mu)| = delta = -log(0.85)
# # w: Weight for borrowing
# #    Set to 0 if no borrowing; Set to NULL if SAM prior
# prior_params <- list(
#   # both = list(treatment.delta = log(0.85), control.delta = log(0.85), treatment.w = NULL, control.w = NULL),
#   # treatment = list(treatment.delta = log(0.85), control.delta = log(0.85), treatment.w = NULL, control.w = 0),
#   # borrowing for treatment with n = 40
#   control = list(treatment.delta = log(0.85), control.delta = log(0.85), treatment.w = 0, control.w = NULL), # borrowing for the control arm
#   neither = list(treatment.delta = log(0.85), control.delta = log(0.85), treatment.w = 0, control.w = 0) # no borrowing
# )
# 
# ## Run simulations
# log_file <- "simulation_gscore_log.txt"
# sink(log_file, append = TRUE, split = FALSE)
# 
# nsim = 1000
# all_results <- lapply(seq_along(data_gen_params_list), function(i) {
#   data_gen_params <- data_gen_params_list[[i]]
#   cat("Running", nsim, "simulations for data_gen_params set", i, "\n\n")
#   for (arm in names(data_gen_params)) {
#     cat("\t Arm:", arm, "\n")
#     cat("\t  n:", data_gen_params[[arm]]$n, "\n")
#     cat("\t  prob:", data_gen_params[[arm]]$prob, "\n")
#     cat("\t  mu:", data_gen_params[[arm]]$mu, "\n")
#     cat("\t  sigma:", data_gen_params[[arm]]$sigma, "\n\n")
#   }
#   t <- system.time({
#     results <- run_simulation(endpoint = "g-score", nsim = nsim,
#                               data_gen_params = data_gen_params,
#                               prior_params = prior_params,
#                               lrv = 0.8, tv = 0.5, fgr = 0.2, fsr = 0.1)
#   })
#   cat("Elapsed time:", t["elapsed"], "seconds\n")
#   cat("=======================================================\n\n")
#   return(results)
# })
# 
# while (sink.number() > 0) {
#   sink(NULL)
# }
# 
# ## Save the posterior parameters, decisions for each run, and OC for each setting
# combined_decisions <- do.call(rbind, lapply(all_results, function(res) res$decisions))
# combined_OC <- do.call(rbind, lapply(all_results, function(res) res$OC))
# combined_post_params <- do.call(rbind, lapply(all_results, function(res) res$post_params))
# 
# saveRDS(combined_post_params, file = "sim_rslt_gscore_post_params_7_8.rds")
# saveRDS(combined_decisions, file = "sim_rslt_gscore_decisions_7_8.rds")
# saveRDS(combined_OC, file = "sim_rslt_gscore_oc_7_8.rds")
# 
# ## Check posterior parameters
# combined_post_params <- readRDS("sim_rslt_gscore_post_params_7_8.rds")
# post_param$control.mu <- as.numeric(post_param$control.mu)
# post_param$control_h.mu <- as.numeric(post_param$control_h.mu)
# post_param$control.mu.logdiff <- as.character(round(exp(post_param$control.mu - post_param$control_h.mu), 2))
# 
# ggplot(post_param, aes(x = control.mu.logdiff, y = control.w1_post, color = control.prob)) +
#   geom_boxplot(width = 0.6, outlier.size = 0.6, outlier.alpha = 0.5) +
#   facet_wrap(~control.n, labeller = label_both, nrow = 1) +
#   labs(x = "Ratio of the mean of g-score > 0 comparing current to historical control",
#        y = "Posterior weight of borrowing",
#        color = "Prob of g-score = 0 in current control",
#        title = "Mean of g-score > 0 in current control = 0.01, delta for SAM = log(0.85)") +
#   theme_bw() +
#   theme(legend.position = "bottom", strip.text.x = element_text(size=10))
# 
# ggsave("prior_data_conflict_weights_gscore_7_8.jpg", width = 12, height = 3.5)
# 
# 
# 
# post_param <- combined_post_params[combined_post_params$control.prob == "0.1", ]
# post_params <- post_param[1, c("control.w1_post", "control.mu1_post", "control.sigma1_post", "control.mu2_post", "control.sigma2_post")]
# names(post_params)[1] <- "control.w_post"
# 
# df <- readRDS("sim_rslt_gscore_decisions_7_8.rds")
# obtain_ESS <- function(post_params, sigma){
#   
#   post <- convert_RBesT_mix(post = post_params, endpoint = "g-score")
#   ess_post <- ess(post, sigma = sigma)
# }
# 
# 
# 
# ## Check the OC
# combined_OC <- readRDS("sim_rslt_gscore_oc_7_8.rds")
# oc <- combined_OC[, c("true_value", "control.n", "borrowing",
#                       "treatment.mu", "control.prob", "control.mu", "control_h.mu",
#                       "decision_pr", "proportion_pr")]
# oc$decision_pr <- factor(oc$decision_pr, levels = c("no-go", "consider", "go"))
# oc$borrowing = ifelse(oc$borrowing == "neither", "No",
#                       ifelse(oc$borrowing == "control", "Yes", oc$borrowing))
# oc$true_value <- round(as.numeric(oc$true_value),2)
# oc$true_value = ifelse(oc$true_value == 0.5, "0.5 (TV)",
#                        ifelse(oc$true_value == 0.8, "0.8 (LRV)", oc$true_value))
# oc$control.mu <- as.numeric(oc$control.mu)
# oc$control_h.mu <- as.numeric(oc$control_h.mu)
# oc$control.mu.logdiff <- as.character(round(exp(oc$control.mu - oc$control_h.mu), 2))
# oc$control.mu.diff <- paste0("log(", as.character(oc$control.mu.logdiff), ")")
# 
# metrics <- oc[oc$true_value %in% c("0.5 (TV)", "0.8 (LRV)"),]
# metrics <- oc[(oc$true_value == "0.8 (LRV)" & oc$decision_pr == "go") | (oc$true_value == "0.5 (TV)" & oc$decision_pr == "no-go"),]
# 
# false_go_risk <- metrics[metrics$true_value == "0.8 (LRV)", c("control.n", "borrowing", "proportion_pr", "control.mu.logdiff")]
# colnames(false_go_risk)[3] <- "false_go_risk"
# false_stop_risk <- metrics[metrics$true_value == "0.5 (TV)", c("control.n", "borrowing", "proportion_pr", "control.mu.logdiff")]
# colnames(false_stop_risk)[3] <- "false_stop_risk"
# metrics_df <- merge(false_go_risk, false_stop_risk, by = c("control.n", "borrowing", "control.mu.logdiff"))
# metrics_long <- melt(metrics_df, id.vars = c("control.n", "borrowing", "control.mu.logdiff"),
#                 measure.vars = c("false_go_risk", "false_stop_risk"),
#                 variable.name = "risk_type", value.name = "risk_value")
# 
# ggplot(metrics_long[metrics_long$borrowing == "Yes",], aes(x = control.mu.logdiff, y = risk_value, color = risk_type)) +
#   geom_point() +
#   facet_wrap(~ control.n, labeller = label_both, nrow = 1) +
#   labs(title = "False Go Risk and False Stop Risk vs. Prior-data Conflict",
#        x = "Ratio of the mean of g-score > 0 comparing current to historical control",
#        y = "Risk Value",
#        color = "Risk Type") +
#   geom_hline(aes(yintercept = 0.2, color = "false_go_risk"), linetype = "dashed") +  # Horizontal line for false go risk
#   geom_hline(aes(yintercept = 0.1, color = "false_stop_risk"), linetype = "dashed") +
#   theme_bw()+
#   theme(legend.position = "bottom", strip.text.x = element_text(size = 10))
# ggsave("prior_data_conflict_risk_gscore_7_8.jpg", width = 12, height = 3.5)
# 
# 
# oc_new <- data.frame()
# for (i in seq(1, nrow(oc), 3)) {
#   tmp <- oc[i:(i+2),]
#   tmp[tmp$decision_pr == "go", "label_ypos"] <- tmp[tmp$decision_pr == "go", "proportion_pr"]
#   tmp[tmp$decision_pr == "consider", "label_ypos"] <- tmp[tmp$decision_pr == "go", "proportion_pr"] + tmp[tmp$decision_pr == "consider", "proportion_pr"]
#   tmp[tmp$decision_pr == "no-go", "label_ypos"] <- 1
#   oc_new <- rbind(oc_new, tmp)
# }
# 
# oc_new <- oc_new[oc_new$control.mu.logdiff == "1", c("true_value", "control.n", "borrowing", "control.prob", "control.mu.logdiff",
#                      "decision_pr", "proportion_pr", "label_ypos")]
# 
# myColors <- c("red","#F0E442","#009E73")
# names(myColors) <- levels(oc_new$decision_pr)
# 
# ggplot(oc_new, aes(x = control.n, y = proportion_pr, fill = decision_pr)) +
#   geom_bar(stat = "identity", width = 1) +
#   geom_hline(yintercept = c(0.2, 0.9), linetype = "dashed") +
#   scale_fill_manual(name = "Decision", values = myColors)+
#   facet_grid(borrowing~true_value, labeller = label_both) +
#   labs(title = "Probability of Each Decision Under Various Sample Sizes (No Prior-data Conflict)", x = "Number of Patients", y = "Probability") +
#   theme(legend.position = "bottom",
#         title = element_text(size = 14),
#         legend.text = element_text(size = 10),
#         strip.text = element_text(size = 12))
# 
# ggsave("sample_size_all_borrowing_gscore_7_8.jpg", width = 22, height = 6)
# 
# lines <- data.frame(true_value = c("0.5 (TV)", "0.8 (LRV)"),
#                     Z = c(0.9, 0.2))
# ggplot(oc_new[oc_new$borrowing %in% c("Yes") & oc_new$true_value %in% c("0.5 (TV)", "0.8 (LRV)"), ],
#        aes(x = control.n, y = proportion_pr, fill = decision_pr)) +
#   geom_bar(stat = "identity") +
#   geom_text(aes(y = label_ypos, label = scales::percent(proportion_pr, 0.1)), vjust = 1.6,
#             size = 3) +
#   scale_fill_manual(name = "Decision", values = myColors)+
#   facet_wrap(~true_value, nrow = 2,
#              labeller = label_both) +
#   geom_hline(data = lines, aes(yintercept = Z), linetype = "dashed") +
#   labs(title = "Probability of Each Decision Under Various Sample Sizes with Borrowing and No Prior-data Conflict", x = "Number of Patients", y = "Probability") +
#   # scale_x_discrete(breaks=seq(15,40,3)) +
#   theme(legend.position = "bottom",
#         title = element_text(size = 14),
#         legend.text = element_text(size = 10),
#         strip.text = element_text(size = 13))
# 
# ggsave("sample_size_threshold_borrowing_gscore_7_8.jpg", width = 12, height = 5)
# 
# 
# oc1 <- oc_new %>%
#   filter(borrowing %in% c("No", "Yes") & control.n == "40")
# 
# ggplot(oc1, aes(x = true_value, y = proportion_pr, fill = decision_pr)) +
#   geom_bar(stat = "identity") +
#   geom_hline(yintercept = c(0.2, 0.9), linetype = "dashed") +
#   # geom_text(aes(label = scales::percent(proportion_pr)), vjust = 1.6, color = "black") +
#   scale_fill_manual(name = "Decision", values = myColors)+
#   facet_grid(~borrowing,
#              labeller = labeller(borrowing = c("No" = "No borrowing",
#                                                "Yes" = "Borrowing for control"))) +
#   labs(title = "Probability of Each Decision Under Sample Size = 40 with No Prior-data Conflict", x = "True Median Ratio", y = "Probability") +
#   theme(title = element_text(size = 12),
#         legend.text = element_text(size = 9),
#         strip.text = element_text(size = 10)) +
#   scale_y_continuous(breaks = seq(0,1, 0.1))
# ggsave("OC_n40_gscore_7_8.jpg", width = 8, height = 4)
# 
# 
# oc2 <- oc_new %>%
#   select(-c(label_ypos, control.prob, control.mu.logdiff)) %>%
#   filter(true_value %in% c("0.5 (TV)", "0.8 (LRV)")) %>%
#   mutate(proportion_pr = scales::percent(proportion_pr, 0.1)) %>%
#   arrange(decision_pr) %>%
#   arrange(true_value) %>%
#   arrange(borrowing) %>%
#   pivot_wider(names_from = c(decision_pr, borrowing), values_from = proportion_pr) %>%
#   arrange(control.n)
# 
# oc2$`no-go_No` = cell_spec(oc2$`no-go_No`,
#                            background = ifelse(oc2$true_value == "0.5 (TV)", "steelblue2", "white"))
# 
# oc2$`no-go_Yes` = cell_spec(oc2$`no-go_Yes`,
#                            background = ifelse(oc2$true_value == "0.5 (TV)", "steelblue2", "white"))
# 
# oc2$`go_No` = cell_spec(oc2$`go_No`,
#                         background = ifelse(oc2$true_value == "0.8 (LRV)", "pink", "white"))
# 
# oc2$`go_Yes` = cell_spec(oc2$`go_Yes`,
#                             background = ifelse(oc2$true_value == "0.8 (LRV)", "pink", "white"))
# 
# kbl(oc2[, c(2,1,3:ncol(oc2))], escape = F,
#     col.names = c("Sample Size", "True value",rep(c("No-Go", "Consider","Go"), 2))) %>%
#   kable_classic(full_width = FALSE) %>%
#   add_header_above(c(" " = 2, "No Borrowing" = 3, "Borrowing (Control)" = 3)) %>%
#   column_spec(1, bold = T) %>%
#   collapse_rows(columns = 1:2, valign = "top")
# 





# 
# # 7/9/2024 Check on the effect of prior-data conflict.
# param_grid <- expand.grid(
#   trt_n = seq(15, 70, 5), # Sample size for the treatment group.
#   ctrl_n = seq(15, 70, 5), # Sample size for the control group.
#   ctrl_h_n = 200, # Sample size for the historical control group.
#   trt_prob = 0.1, # Probability of zero g-scores in the treatment group.
#   ctrl_prob = 0.1, # Probability of zero g-scores in the control group.
#   ctrl_h_prob = 0.1, # Probability of zero g-scores in the historical control group.
#   trt_mu = 0.008, # Mean for the non-zero g-scores in the treatment group.
#   ctrl_mu = 0.01, # Mean for the non-zero g-scores in the control group.
#   ctrl_h_mu = c(0.01 / seq(0.5, 1, 0.05), 0.01 * seq(0.5, 0.95, 0.05)), # Mean for the non-zero g-scores in the historical control group.
#   trt_sigma = 1, # Standard deviation for the non-zero g-scores in the treatment group.
#   ctrl_sigma = 1, # Standard deviation for the non-zero g-scores in the control group.
#   ctrl_h_sigma = 1, # Standard deviation for the non-zero g-scores in the historical control group.
#   stringsAsFactors = FALSE
# ) %>%
#   filter(trt_n == ctrl_n)
# 
# ## Create a list of parameters used for data generation.
# # Note that the mu's are taken logarithm since non-zero g-score follows log-normal(mu, sigma)
# data_gen_params_list <- lapply(apply(param_grid, 1, as.list),
#                                create_data_gen_params, endpoint = "g-score")
# 
# ## Create a list of prior parameters
# # delta: Clinically significant difference (CSD) in treatment effect, as the threshold for prior-data conflict.
# #        H_0: log(ctrl_mu) = log(ctrl_h_mu) vs H_1: |log(ctrl_h_mu) - log(ctrl_mu)| = delta = -log(0.85)
# # w: Weight for borrowing
# #    Set to 0 if no borrowing; Set to NULL if SAM prior
# prior_params <- list(
#   control4 = list(control.delta = log(0.5),  treatment.w = 0, control.w = NULL),
#   control5 = list(control.delta = log(0.6),  treatment.w = 0, control.w = NULL),
#   control6 = list(control.delta = log(0.7),  treatment.w = 0, control.w = NULL),
#   control7 = list(control.delta = log(0.8),  treatment.w = 0, control.w = NULL),
#   control9 = list(control.delta = log(0.9),  treatment.w = 0, control.w = NULL)
# )
# 
# ## Run simulations
# log_file <- "simulation_gscore_log_7_9.txt"
# sink(log_file, append = TRUE, split = FALSE)
# 
# nsim = 1000
# all_results <- lapply(seq_along(data_gen_params_list), function(i) {
#   data_gen_params <- data_gen_params_list[[i]]
#   cat("Running", nsim, "simulations for data_gen_params set", i, "\n\n")
#   for (arm in names(data_gen_params)) {
#     cat("\t Arm:", arm, "\n")
#     cat("\t  n:", data_gen_params[[arm]]$n, "\n")
#     cat("\t  prob:", data_gen_params[[arm]]$prob, "\n")
#     cat("\t  mu:", data_gen_params[[arm]]$mu, "\n")
#     cat("\t  sigma:", data_gen_params[[arm]]$sigma, "\n\n")
#   }
#   t <- system.time({
#     results <- run_simulation(endpoint = "g-score", nsim = nsim,
#                               data_gen_params = data_gen_params,
#                               prior_params = prior_params,
#                               lrv = 0.8, tv = 0.5, fgr = 0.2, fsr = 0.1)
#   })
#   cat("Elapsed time:", t["elapsed"], "seconds\n")
#   cat("=======================================================\n\n")
#   return(results)
# })
# 
# while (sink.number() > 0) {
#   sink(NULL)
# }
# 
# # 
# # ## Save the posterior parameters, decisions for each run, and OC for each setting
# # combined_decisions1 <- do.call(rbind, lapply(all_results, function(res) res$decisions))
# # combined_OC1 <- do.call(rbind, lapply(all_results, function(res) res$OC))
# # combined_post_params1 <- do.call(rbind, lapply(all_results, function(res) res$post_params))
# # 
# # 
# # combined_post_params <- readRDS("sim_rslt_gscore_post_params_7_9.rds")
# # combined_decisions <- readRDS("sim_rslt_gscore_decisions_7_9.rds")
# # combined_OC <- readRDS("sim_rslt_gscore_oc_7_9.rds")
# # 
# # 
# # combined_post_params <- bind_rows(combined_post_params, combined_post_params1)
# # combined_decisions <- bind_rows(combined_decisions, combined_decisions1)
# # combined_OC <- bind_rows(combined_OC, combined_OC1)
# 
# 
# saveRDS(combined_post_params, file = "sim_rslt_gscore_post_params_7_9.rds")
# saveRDS(combined_decisions, file = "sim_rslt_gscore_decisions_7_9.rds")
# saveRDS(combined_OC, file = "sim_rslt_gscore_oc_7_9.rds")
# 
# 
# ## Check posterior weights
# combined_post_params <- readRDS("sim_rslt_gscore_post_params_7_9.rds")
# post_param <- combined_post_params[, c("control.n", "control.delta",
#                                      "control.mu", "control_h.prob", "control_h.mu",
#                                      "control.w_prior", "control.w1_post", "control.w2_post")]
# 
# post_param$control.mu <- as.numeric(post_param$control.mu)
# post_param$control_h.mu <- as.numeric(post_param$control_h.mu)
# post_param$control.mu.logdiff <- as.character(round(exp(post_param$control.mu - post_param$control_h.mu), 2))
# post_param$control.delta <- round(exp(as.numeric(post_param$control.delta)), 1)
# 
# post_p_list <- list()
# for (delta in c(0.2, 0.3, 0.4)) {
#   df <- post_param[post_param$control.delta == delta,]
#   df$control.mu.logdiff <- as.numeric(df$control.mu.logdiff)
#   df$control.mu.logdiff <- factor(df$control.mu.logdiff, levels = sort(unique(df$control.mu.logdiff)))
# 
#   p <- ggplot(df, aes(x = control.mu.logdiff, y = control.w1_post)) +
#     geom_boxplot(notch = FALSE, width = 0.6, outlier.size = 0.6, outlier.alpha = 0.5) +
#     facet_wrap(~control.n, labeller = label_both, nrow = 2) +
#     scale_x_discrete(breaks = levels(df$control.mu.logdiff), labels = levels(df$control.mu.logdiff)) +
#     labs(
#       x = "Ratio of the mean of g-score > 0 comparing current to historical control",
#       y = "Posterior weight of borrowing",
#       title = paste0("delta = ", delta)
#     ) +
#     theme_bw() +
#     theme(
#       strip.text.x = element_text(size = 10),
#       axis.text.x = element_text(size = 8, angle = 45, hjust = 1)
#     )
# 
#   post_p_list[[as.character(delta)]] <- p
# }
# 
# for (delta in c(0.5, 0.6, 0.7, 0.8, 0.9)) {
#   df <- post_param[post_param$control.delta == delta,]
#   df$control.mu.logdiff <- as.numeric(df$control.mu.logdiff)
#   df$control.mu.logdiff <- factor(df$control.mu.logdiff, levels = sort(unique(df$control.mu.logdiff)))
# 
#   delta_factor <- as.character(delta)
#   delta_inv_factor <- as.character(round(1 / delta, 2))
# 
#   # Create the plot
#   p <- ggplot(df, aes(x = control.mu.logdiff, y = control.w1_post)) +
#     geom_boxplot(notch = FALSE, width = 0.6, outlier.size = 0.6, outlier.alpha = 0.5) +
#     facet_wrap(~control.n, labeller = label_both, nrow = 2) +
#     geom_vline(xintercept = which(levels(df$control.mu.logdiff) == delta_factor), linetype = "dashed", color = "red") +
#     geom_vline(xintercept = which(levels(df$control.mu.logdiff) == delta_inv_factor), linetype = "dashed", color = "red") +
#     scale_x_discrete(breaks = levels(df$control.mu.logdiff), labels = levels(df$control.mu.logdiff)) +
#     labs(
#       x = "Ratio of the mean of g-score > 0 comparing current to historical control",
#       y = "Posterior weight of borrowing",
#       title = paste0("delta = ", delta)
#     ) +
#     theme_bw() +
#     theme(
#       strip.text.x = element_text(size = 10),
#       axis.text.x = element_text(size = 8, angle = 45, hjust = 1)
#     )
# 
#   post_p_list[[as.character(delta)]] <- p
# }
# 
# post_p_list[[1]] / post_p_list[[2]] / post_p_list[[3]]  +
#   plot_annotation(title = 'Prob of zero g-score in current and historical control = 0.1, Mean of positive g-score in current control = 0.01')
# ggsave("prior_data_conflict_post_weights_gscore_7_9_1.jpg", width = 18, height = 15)
# 
# post_p_list[[4]] / post_p_list[[5]] / post_p_list[[6]] / post_p_list[[7]] / post_p_list[[8]]  +
#   plot_annotation(title = 'Prob of zero g-score in current and historical control = 0.1, Mean of positive g-score in current control = 0.01')
# ggsave("prior_data_conflict_post_weights_gscore_7_9_2.jpg", width = 18, height = 25)
# 
# 
# ## Check prior weights
# 
# prior_p_list <- list()
# for (delta in c(0.2, 0.3, 0.4)) {
#   df <- post_param[post_param$control.delta == delta,]
#   df$control.mu.logdiff <- as.numeric(df$control.mu.logdiff)
#   df$control.mu.logdiff <- factor(df$control.mu.logdiff, levels = sort(unique(df$control.mu.logdiff)))
# 
#   p <- ggplot(df, aes(x = control.mu.logdiff, y = control.w_prior)) +
#     geom_boxplot(notch = FALSE, width = 0.6, outlier.size = 0.6, outlier.alpha = 0.5) +
#     facet_wrap(~control.n, labeller = label_both, nrow = 2) +
#     scale_x_discrete(breaks = levels(df$control.mu.logdiff), labels = levels(df$control.mu.logdiff)) +
#     labs(
#       x = "Ratio of the mean of g-score > 0 comparing current to historical control",
#       y = "Prior weight of borrowing",
#       title = paste0("delta = ", delta)
#     ) +
#     theme_bw() +
#     theme(
#       strip.text.x = element_text(size = 10),
#       axis.text.x = element_text(size = 8, angle = 45, hjust = 1)
#     )
# 
#   prior_p_list[[as.character(delta)]] <- p
# }
# 
# for (delta in c(0.5, 0.6, 0.7, 0.8, 0.9)) {
#   df <- post_param[post_param$control.delta == delta,]
#   df$control.mu.logdiff <- as.numeric(df$control.mu.logdiff)
#   df$control.mu.logdiff <- factor(df$control.mu.logdiff, levels = sort(unique(df$control.mu.logdiff)))
# 
#   delta_factor <- as.character(delta)
#   delta_inv_factor <- as.character(round(1 / delta, 2))
# 
#   p <- ggplot(df, aes(x = control.mu.logdiff, y = control.w_prior)) +
#     geom_boxplot(notch = FALSE, width = 0.6, outlier.size = 0.6, outlier.alpha = 0.5) +
#     facet_wrap(~control.n, labeller = label_both, nrow = 2) +
#     geom_vline(xintercept = which(levels(df$control.mu.logdiff) == delta_factor), linetype = "dashed", color = "red") +
#     geom_vline(xintercept = which(levels(df$control.mu.logdiff) == delta_inv_factor), linetype = "dashed", color = "red") +
#     scale_x_discrete(breaks = levels(df$control.mu.logdiff), labels = levels(df$control.mu.logdiff)) +
#     labs(
#       x = "Ratio of the mean of g-score > 0 comparing current to historical control",
#       y = "Prior weight of borrowing",
#       title = paste0("delta = ", delta)
#     ) +
#     theme_bw() +
#     theme(
#       strip.text.x = element_text(size = 10),
#       axis.text.x = element_text(size = 8, angle = 45, hjust = 1)
#     )
# 
#   prior_p_list[[as.character(delta)]] <- p
# }
# 
# prior_p_list[[1]] / prior_p_list[[2]] / prior_p_list[[3]]  +
#   plot_annotation(title = 'Prob of zero g-score in current and historical control = 0.1, Mean of positive g-score in current control = 0.01')
# ggsave("prior_data_conflict_prior_weights_gscore_7_9_1.jpg", width = 18, height = 15)
# 
# 
# prior_p_list[[4]] / prior_p_list[[5]] / prior_p_list[[6]] / prior_p_list[[7]] / prior_p_list[[8]]  +
#   plot_annotation(title = 'Prob of zero g-score in current and historical control = 0.1, Mean of positive g-score in current control = 0.01')
# ggsave("prior_data_conflict_prior_weights_gscore_7_9_2.jpg", width = 18, height = 25)
# 
# 
# ## Check difference in prior and posterior weights
# 
# diff_p_list <- list()
# for (delta in c(0.2, 0.3, 0.4)) {
#   df <- post_param[post_param$control.delta == delta,]
#   df$control.mu.logdiff <- as.numeric(df$control.mu.logdiff)
#   df$control.mu.logdiff <- factor(df$control.mu.logdiff, levels = sort(unique(df$control.mu.logdiff)))
#   df$control.w.diff <- df$control.w_prior-df$control.w1_post
# 
#   p <- ggplot(df, aes(x = control.mu.logdiff, y = control.w.diff)) +
#     geom_boxplot(notch = FALSE, width = 0.6, outlier.size = 0.6, outlier.alpha = 0.5) +
#     facet_wrap(~control.n, labeller = label_both, nrow = 2) +
#     scale_x_discrete(breaks = levels(df$control.mu.logdiff), labels = levels(df$control.mu.logdiff)) +
#     labs(
#       x = "Ratio of the mean of g-score > 0 comparing current to historical control",
#       y = "Prior Weight - Posterior Weight",
#       title = paste0("delta = ", delta)
#     ) +
#     theme_bw() +
#     theme(
#       strip.text.x = element_text(size = 10),
#       axis.text.x = element_text(size = 8, angle = 45, hjust = 1)
#     )
# 
#   diff_p_list[[as.character(delta)]] <- p
# }
# 
# for (delta in c(0.5, 0.6, 0.7, 0.8, 0.9)) {
#   df <- post_param[post_param$control.delta == delta,]
#   df$control.mu.logdiff <- as.numeric(df$control.mu.logdiff)
#   df$control.mu.logdiff <- factor(df$control.mu.logdiff, levels = sort(unique(df$control.mu.logdiff)))
#   df$control.w.diff <- df$control.w_prior-df$control.w1_post
# 
#   delta_factor <- as.character(delta)
#   delta_inv_factor <- as.character(round(1 / delta, 2))
# 
#   p <- ggplot(df, aes(x = control.mu.logdiff, y = control.w.diff)) +
#     geom_boxplot(notch = FALSE, width = 0.6, outlier.size = 0.6, outlier.alpha = 0.5) +
#     facet_wrap(~control.n, labeller = label_both, nrow = 2) +
#     geom_hline(yintercept = 0, linetype = "dashed", color = "blue") +
#     geom_vline(xintercept = which(levels(df$control.mu.logdiff) == delta_factor), linetype = "dashed", color = "red") +
#     geom_vline(xintercept = which(levels(df$control.mu.logdiff) == delta_inv_factor), linetype = "dashed", color = "red") +
#     scale_x_discrete(breaks = levels(df$control.mu.logdiff), labels = levels(df$control.mu.logdiff)) +
#     labs(
#       x = "Ratio of the mean of g-score > 0 comparing current to historical control",
#       y =  "Prior Weight - Posterior Weight",
#       title = paste0("delta = ", delta)
#     ) +
#     theme_bw() +
#     theme(
#       strip.text.x = element_text(size = 10),
#       axis.text.x = element_text(size = 8, angle = 45, hjust = 1)
#     )
# 
#   diff_p_list[[as.character(delta)]] <- p
# }
# 
# diff_p_list[[1]] / diff_p_list[[2]] / diff_p_list[[3]]  +
#   plot_annotation(title = 'Prob of zero g-score in current and historical control = 0.1, Mean of positive g-score in current control = 0.01')
# ggsave("prior_data_conflict_diff_weights_gscore_7_9_1.jpg", width = 18, height = 15)
# 
# diff_p_list[["0.5"]] / diff_p_list[["0.6"]] / diff_p_list["0.7"] / diff_p_list[["0.8"]] / diff_p_list[["0.9"]]  +
#   plot_annotation(title = 'Prob of zero g-score in current and historical control = 0.1, Mean of positive g-score in current control = 0.01')
# ggsave("prior_data_conflict_diff_weights_gscore_7_9_2.jpg", width = 18, height = 25)
# 
# 
# ## Check the OC
# combined_OC <- readRDS("sim_rslt_gscore_oc_7_9.rds")
# oc <- combined_OC[, c("true_value", "control.n", "control.delta",
#                       "treatment.mu", "control.prob", "control.mu", "control_h.mu",
#                       "decision_pr", "proportion_pr")]
# oc$decision_pr <- factor(oc$decision_pr, levels = c("no-go", "consider", "go"))
# oc$true_value <- round(as.numeric(oc$true_value),2)
# oc$true_value = ifelse(oc$true_value == 0.5, "0.5 (TV)",
#                        ifelse(oc$true_value == 0.8, "0.8 (LRV)", oc$true_value))
# oc$control.mu <- as.numeric(oc$control.mu)
# oc$control_h.mu <- as.numeric(oc$control_h.mu)
# oc$control.mu.logdiff <- as.character(round(exp(oc$control.mu - oc$control_h.mu), 2))
# oc$control.mu.diff <- paste0("log(", as.character(oc$control.mu.logdiff), ")")
# oc$control.delta <- round(exp(as.numeric(oc$control.delta)), 1)
# 
# metrics <- oc[(oc$true_value == "0.8 (LRV)" & oc$decision_pr == "go") | (oc$true_value == "0.5 (TV)" & oc$decision_pr == "no-go"),]
# 
# false_go_risk <- metrics[metrics$true_value == "0.8 (LRV)", c("control.n", "control.delta", "control.mu.logdiff", "proportion_pr")]
# colnames(false_go_risk)[4] <- "false_go_risk"
# false_stop_risk <- metrics[metrics$true_value == "0.5 (TV)", c("control.n", "control.delta", "control.mu.logdiff", "proportion_pr")]
# colnames(false_stop_risk)[4] <- "false_stop_risk"
# metrics_df <- merge(false_go_risk, false_stop_risk, by = c("control.n", "control.mu.logdiff", "control.delta"))
# metrics_long <- melt(metrics_df, id.vars = c("control.n", "control.mu.logdiff", "control.delta"), 
#                      measure.vars = c("false_go_risk", "false_stop_risk"), 
#                      variable.name = "risk_type", value.name = "risk_value")
# 
# 
# risk_p_list <- list()
# for (delta in c(0.5, 0.6, 0.7, 0.8, 0.9)) {
#   df <- metrics_long[metrics_long$control.delta == delta,]
#   df$control.mu.logdiff <- as.numeric(df$control.mu.logdiff)
#   df$control.mu.logdiff <- factor(df$control.mu.logdiff, levels = sort(unique(df$control.mu.logdiff)))
#  
#   delta_factor <- as.character(delta)
#   delta_inv_factor <- as.character(round(1 / delta, 2))
#   
#   p <- ggplot(df, aes(x = control.mu.logdiff, y = risk_value, color = risk_type)) +
#     geom_point() +
#     facet_wrap(~ control.n, labeller = label_both, nrow = 1) +
#     geom_hline(aes(yintercept = 0.2, color = "false_go_risk"), linetype = "dashed") +  # Horizontal line for false go risk
#     geom_hline(aes(yintercept = 0.1, color = "false_stop_risk"), linetype = "dashed") +
#     geom_vline(xintercept = which(levels(df$control.mu.logdiff) == delta_factor), linetype = "dashed", color = "black") +
#     geom_vline(xintercept = which(levels(df$control.mu.logdiff) == delta_inv_factor), linetype = "dashed", color = "black") +
#     scale_x_discrete(breaks = levels(df$control.mu.logdiff), labels = levels(df$control.mu.logdiff)) +
#     labs(title = paste0("delta = ", delta),
#          x = "Ratio of the mean of g-score > 0 comparing current to historical control",
#          y = "Risk Value",
#          color = "Risk Type") +
#     theme_bw() +
#     theme(
#       legend.position = "bottom",
#       strip.text.x = element_text(size = 10),
#       axis.text.x = element_text(size = 7, angle = 45, hjust = 1)
#     )
#   
#   risk_p_list[[as.character(delta)]] <- p
# }
# 
# risk_p_list[["0.5"]] / risk_p_list[["0.6"]] / risk_p_list["0.7"] / risk_p_list[["0.8"]] / risk_p_list[["0.9"]]  +
#   plot_annotation(title = 'Prob of zero g-score in current and historical control = 0.1, Mean of positive g-score in current control = 0.01')
# ggsave("prior_data_conflict_risk_gscore_7_9.jpg", width = 23.5, height = 15)
# 
# 


# # 7/10/2024: Try fixed prior weight at the average prior weight when delta = 0.8
# param_grid <- expand.grid(
#   trt_n = seq(15, 70, 5), # Sample size for the treatment group.
#   ctrl_n = seq(15, 70, 5), # Sample size for the control group.
#   ctrl_h_n = 200, # Sample size for the historical control group.
#   trt_prob = 0.1, # Probability of zero g-scores in the treatment group.
#   ctrl_prob = 0.1, # Probability of zero g-scores in the control group.
#   ctrl_h_prob = 0.1, # Probability of zero g-scores in the historical control group.
#   trt_mu = c(0.005, 0.008), # Mean for the non-zero g-scores in the treatment group.
#   ctrl_mu = 0.01, # Mean for the non-zero g-scores in the control group.
#   ctrl_h_mu = c(0.01 / seq(0.5, 1, 0.05), 0.01 * seq(0.5, 0.95, 0.05)), # Mean for the non-zero g-scores in the historical control group.
#   trt_sigma = 1, # Standard deviation for the non-zero g-scores in the treatment group.
#   ctrl_sigma = 1, # Standard deviation for the non-zero g-scores in the control group.
#   ctrl_h_sigma = 1, # Standard deviation for the non-zero g-scores in the historical control group.
#   stringsAsFactors = FALSE
# ) %>%
#   filter(trt_n == ctrl_n)
# 
# ## Create a list of parameters used for data generation.
# # Note that the mu's are taken logarithm since non-zero g-score follows log-normal(mu, sigma)
# data_gen_params_list <- lapply(apply(param_grid, 1, as.list),
#                                create_data_gen_params, endpoint = "g-score")
# 
# combined_post_params$control.delta
# ## Create a list of prior parameters
# combined_post_params <- readRDS("sim_rslt_gscore_post_params_7_9.rds")
# avg_prior_w <- combined_post_params %>%
#   group_by(control.delta) %>%
#   mutate(control.delta = round(exp(as.numeric(control.delta)), 1)) %>%
#   summarize(prior_w_mean = mean(control.w_prior))
# 
# w <- 0.3
# prior_params <- list(
#   control = list(treatment.w = 0, control.w = 0.3)
# )
# 
# ## Run simulations
# log_file <- "simulation_gscore_log_7_10.txt"
# sink(log_file, append = TRUE, split = FALSE)
# 
# nsim = 1000
# all_results <- lapply(seq_along(data_gen_params_list), function(i) {
#   data_gen_params <- data_gen_params_list[[i]]
#   cat("Running", nsim, "simulations for data_gen_params set", i, "\n\n")
#   for (arm in names(data_gen_params)) {
#     cat("\t Arm:", arm, "\n")
#     cat("\t  n:", data_gen_params[[arm]]$n, "\n")
#     cat("\t  prob:", data_gen_params[[arm]]$prob, "\n")
#     cat("\t  mu:", data_gen_params[[arm]]$mu, "\n")
#     cat("\t  sigma:", data_gen_params[[arm]]$sigma, "\n\n")
#   }
#   t <- system.time({
#     results <- run_simulation(endpoint = "g-score", nsim = nsim,
#                               data_gen_params = data_gen_params,
#                               prior_params = prior_params,
#                               lrv = 0.8, tv = 0.5, fgr = 0.2, fsr = 0.1)
#   })
#   cat("Elapsed time:", t["elapsed"], "seconds\n")
#   cat("=======================================================\n\n")
#   return(results)
# })
# 
# while (sink.number() > 0) {
#   sink(NULL)
# }
# 
# 
# ## Save the posterior parameters, decisions for each run, and OC for each setting
# combined_decisions <- do.call(rbind, lapply(all_results, function(res) res$decisions))
# combined_OC <- do.call(rbind, lapply(all_results, function(res) res$OC))
# combined_post_params <- do.call(rbind, lapply(all_results, function(res) res$post_params))
# 
# saveRDS(combined_post_params, file = "sim_rslt_gscore_post_params_7_10.rds")
# saveRDS(combined_decisions, file = "sim_rslt_gscore_decisions_7_10.rds")
# saveRDS(combined_OC, file = "sim_rslt_gscore_oc_7_10.rds")
# 
# ## Check posterior weights
# combined_post_params <- readRDS("sim_rslt_gscore_post_params_7_10.rds")
# post_param <- combined_post_params[, c("control.n", "control.mu", "control_h.prob", "control_h.mu",
#                                      "control.w_prior", "control.w1_post")]
# post_param$control.mu <- as.numeric(post_param$control.mu)
# post_param$control_h.mu <- as.numeric(post_param$control_h.mu)
# post_param$control.mu.logdiff <- as.character(round(exp(post_param$control.mu - post_param$control_h.mu), 2))
# 
# df <- post_param
# df$control.mu.logdiff <- as.numeric(df$control.mu.logdiff)
# df$control.mu.logdiff <- factor(df$control.mu.logdiff, levels = sort(unique(df$control.mu.logdiff)))
# 
# ggplot(df, aes(x = control.mu.logdiff, y = control.w1_post)) +
#   geom_boxplot(notch = FALSE, width = 0.6, outlier.size = 0.6, outlier.alpha = 0.5) +
#   geom_hline(yintercept = 0.3, linetype = "dashed", color = "red") +
#   facet_wrap(~control.n, labeller = label_both, nrow = 2) +
#   scale_x_discrete(breaks = levels(df$control.mu.logdiff), labels = levels(df$control.mu.logdiff)) +
#   labs(
#     x = "Ratio of the mean of g-score > 0 comparing current to historical control",
#     y = "Posterior weight of borrowing",
#     title = "Prob of zero g-score in current and historical control = 0.1, Mean of positive g-score in current control = 0.01, Prior weight of borrowing = 0.3"
#   ) +
#   theme_bw() +
#   theme(
#     strip.text.x = element_text(size = 10),
#     axis.text.x = element_text(size = 8, angle = 45, hjust = 1)
#   )
# ggsave("prior_data_conflict_post_weights_gscore_fixed_prior_7_10.jpg", width = 18, height = 5)
# 
# ## Check difference in prior and posterior weights
# 
# df$control.w.diff <- df$control.w_prior-df$control.w1_post
# ggplot(df, aes(x = control.mu.logdiff, y = control.w.diff)) +
#   geom_boxplot(notch = FALSE, width = 0.6, outlier.size = 0.6, outlier.alpha = 0.5) +
#   facet_wrap(~control.n, labeller = label_both, nrow = 2) +
#   scale_x_discrete(breaks = levels(df$control.mu.logdiff), labels = levels(df$control.mu.logdiff)) +
#   geom_hline(yintercept = 0, linetype = "dashed", color = "red") +
#   labs(
#     x = "Ratio of the mean of g-score > 0 comparing current to historical control",
#     y = "Prior Weight - Posterior Weight",
#     title = 'Prob of zero g-score in current and historical control = 0.1, Mean of positive g-score in current control = 0.01, Prior weight of borrowing = 0.3'
#   ) +
#   theme_bw() +
#   theme(
#     strip.text.x = element_text(size = 10),
#     axis.text.x = element_text(size = 8, angle = 45, hjust = 1)
#   )
# ggsave("prior_data_conflict_diff_weights_gscore_fixed_prior_7_10.jpg", width = 18, height = 5)
# 
# 
# ## Check the OC
# combined_OC <- readRDS("sim_rslt_gscore_oc_7_10.rds")
# oc <- combined_OC[, c("true_value", "control.n", "treatment.mu", "control.prob", "control.mu", "control_h.mu",
#                       "decision_pr", "proportion_pr")]
# oc$decision_pr <- factor(oc$decision_pr, levels = c("no-go", "consider", "go"))
# oc$true_value <- round(as.numeric(oc$true_value),2)
# oc$true_value = ifelse(oc$true_value == 0.5, "0.5 (TV)",
#                        ifelse(oc$true_value == 0.8, "0.8 (LRV)", oc$true_value))
# oc$control.mu <- as.numeric(oc$control.mu)
# oc$control_h.mu <- as.numeric(oc$control_h.mu)
# oc$control.mu.logdiff <- as.character(round(exp(oc$control.mu - oc$control_h.mu), 2))
# oc$control.mu.diff <- paste0("log(", as.character(oc$control.mu.logdiff), ")")
# 
# metrics <- oc[(oc$true_value == "0.8 (LRV)" & oc$decision_pr == "go") | (oc$true_value == "0.5 (TV)" & oc$decision_pr == "no-go"),]
# 
# false_go_risk <- metrics[metrics$true_value == "0.8 (LRV)", c("control.n", "control.mu.logdiff", "proportion_pr")]
# colnames(false_go_risk)[3] <- "false_go_risk"
# false_stop_risk <- metrics[metrics$true_value == "0.5 (TV)", c("control.n", "control.mu.logdiff", "proportion_pr")]
# colnames(false_stop_risk)[3] <- "false_stop_risk"
# metrics_df <- merge(false_go_risk, false_stop_risk, by = c("control.n", "control.mu.logdiff"))
# metrics_long <- melt(metrics_df, id.vars = c("control.n", "control.mu.logdiff"),
#                      measure.vars = c("false_go_risk", "false_stop_risk"),
#                      variable.name = "risk_type", value.name = "risk_value")
# 
# df <- metrics_long
# df$control.mu.logdiff <- as.numeric(df$control.mu.logdiff)
# df$control.mu.logdiff <- factor(df$control.mu.logdiff, levels = sort(unique(df$control.mu.logdiff)))
# 
# ggplot(df, aes(x = control.mu.logdiff, y = risk_value, color = risk_type)) +
#   geom_point() +
#   facet_wrap(~ control.n, labeller = label_both, nrow = 1) +
#   geom_hline(aes(yintercept = 0.2, color = "false_go_risk"), linetype = "dashed") +  
#   geom_hline(aes(yintercept = 0.1, color = "false_stop_risk"), linetype = "dashed") +
#   scale_x_discrete(breaks = levels(df$control.mu.logdiff), labels = levels(df$control.mu.logdiff)) +
#   labs(title = "Prob of zero g-score in current and historical control = 0.1, Mean of positive g-score in current control = 0.01, Prior weight of borrowing = 0.3",
#        x = "Ratio of the mean of g-score > 0 comparing current to historical control",
#        y = "Risk Value",
#        color = "Risk Type") +
#   theme_bw() +
#   theme(
#     legend.position = "bottom",
#     strip.text.x = element_text(size = 10),
#     axis.text.x = element_text(size = 7, angle = 45, hjust = 1)
#   )
# ggsave("prior_data_conflict_risk_gscore_fixed_prior_7_10.jpg", width = 23.5, height = 3)
# 


# # 7/11/2024: Compare the distribution of g-score and posterior distribution 
# param_grid <- expand.grid(
#   ctrl_n = seq(10,50,5), # Sample size for the control group.
#   ctrl_h_n = 200, # Sample size for the historical control group.
#   ctrl_prob = c(0.1, 0.2, 0.3, 0.4), # Probability of zero g-scores in the control group.
#   ctrl_h_prob = c(0.1, 0.2, 0.3, 0.4), # Probability of zero g-scores in the historical control group.
#   ctrl_mu = 0.01, # Mean for the non-zero g-scores in the control group.
#   ctrl_h_mu = c(0.01 / seq(0.75, 0.95, 0.1), 0.01, 0.01 * seq(0.75, 0.95, 0.1)), # Mean for the non-zero g-scores in the historical control group.
#   ctrl_sigma = 1, # Standard deviation for the non-zero g-scores in the control group.
#   ctrl_h_sigma = 1, # Standard deviation for the non-zero g-scores in the historical control group.
#   stringsAsFactors = FALSE
# ) 
# 
# ## Create a list of parameters used for data generation. 
# # Note that the mu's are taken logarithm since non-zero g-score follows log-normal(mu, sigma)
# data_gen_params_list <- lapply(apply(param_grid, 1, as.list), 
#                                create_data_gen_params, endpoint = "g-score")
# 
# ## Create a list of prior parameters 
# prior_params <- list(
#   control = list(control.delta = log(0.85), control.w = NULL)
# )
# 
# ## Run simulations
# log_file <- "simulation_gscore_log_7_11.txt"
# sink(log_file, append = TRUE, split = FALSE)
# 
# nsim = 1000
# all_results <- lapply(seq_along(data_gen_params_list), function(i) {
#   data_gen_params <- data_gen_params_list[[i]]
#   cat("Running", nsim, "simulations for data_gen_params set", i, "\n\n")
#   for (arm in names(data_gen_params)) {
#     cat("\t Arm:", arm, "\n")
#     cat("\t  n:", data_gen_params[[arm]]$n, "\n")
#     cat("\t  prob:", data_gen_params[[arm]]$prob, "\n")
#     cat("\t  mu:", data_gen_params[[arm]]$mu, "\n")
#     cat("\t  sigma:", data_gen_params[[arm]]$sigma, "\n\n")
#   }
#   t <- system.time({
#     results <- run_simulation(endpoint = "g-score", nsim = nsim, 
#                               data_gen_params = data_gen_params, 
#                               prior_params = prior_params,
#                               lrv = 0.8, tv = 0.5, fgr = 0.2, fsr = 0.1, posterior_infer = F,
#                               Lalonde_decision = F)
#   })
#   cat("Elapsed time:", t["elapsed"], "seconds\n")
#   cat("=======================================================\n\n")
#   return(results)
# })
# 
# while (sink.number() > 0) {
#   sink(NULL)
# }
# 
# combined_post_params <- do.call(rbind, lapply(all_results, function(res) res$post_params))
# saveRDS(combined_post_params, file = "sim_rslt_gscore_post_params_7_11.rds")
# 
# 
# # Evaluate the normal approximation to the distribution
# n_samples <- 10000
# combined_post_params <- readRDS("sim_rslt_gscore_post_params_7_11.rds")
# for (i in 1:nrow(post_params)) {
#   post_params <- as.numeric(combined_post_params[i,])
#   names(post_params) <- colnames(combined_post_params)
#   
#   current_prob <- post_params["control.prob"]
#   historical_prob <- post_params["control_h.prob"]
#   current_mu <- post_params["control.mu"]
#   historical_mu <- post_params["control_h.mu"]
#   current_sigma <- post_params["control.sigma"]
#   historical_sigma <- post_params["control_h.sigma"]
#   
#   # Number of samples
#   n_samples <- 100000
#   
#   # Generate current zero-inflated log-normal samples
#   log_normal_samples_current <- rlnorm(n_samples, meanlog = current_mu, sdlog = current_sigma)
#   zero_inflated_samples_current <- ifelse(runif(n_samples) < current_prob, 0, log_normal_samples_current)
#   data_current <- data.frame(samples = zero_inflated_samples_current, type = "Current")
#   
#   # Generate historical zero-inflated log-normal samples
#   log_normal_samples_historical <- rlnorm(n_samples, meanlog = historical_mu, sdlog = historical_sigma)
#   zero_inflated_samples_historical <- ifelse(runif(n_samples) < historical_prob, 0, log_normal_samples_historical)
#   data_historical <- data.frame(samples = zero_inflated_samples_historical, type = "Historical")
#   
# 
#   # Combine data
#   data <- rbind(data_current, data_historical)
#   
#   # Plot zero-inflated log-normal distributions
#   ggplot(data, aes(x = samples)) +
#     geom_histogram(aes(y = ..density..), bins = 1000, alpha = 0.6) +
#     facet_wrap(~ type) +
#     labs(title = "Zero-Inflated Log-Normal Distributions", x = "Value", y = "Density") +
#     theme_minimal()
#   
#   
#   post <- convert_RBesT_mix(post = post_params[endsWith(names(post_params), "_post")], endpoint = "g-score")
#   dmix(post,seq(0,1, 0.01))
# }
# 




# # 7/12/2024
# param_grid <- expand.grid(
#   trt_n =seq(10,40,5), # Sample size for the treatment group.
#   ctrl_n = seq(10,40,5), # Sample size for the control group.
#   ctrl_h_n = 200, # Sample size for the historical control group.
#   trt_prob = c(0.1, 0.2, 0.3, 0.4), # Probability of zero g-scores in the treatment group.
#   ctrl_prob = c(0.1, 0.2, 0.3, 0.4), # Probability of zero g-scores in the control group.
#   ctrl_h_prob = c(0.1, 0.2, 0.3, 0.4), # Probability of zero g-scores in the historical control group.
#   trt_mu = c(0.005, 0.008), # Mean for the non-zero g-scores in the treatment group.
#   ctrl_mu = 0.01, # Mean for the non-zero g-scores in the control group.
#   ctrl_h_mu = c(0.01 / seq(0.75, 0.95, 0.1), 0.01, 0.01 * seq(0.75, 0.95, 0.1)), # Mean for the non-zero g-scores in the historical control group.
#   trt_sigma = 1, # Standard deviation for the non-zero g-scores in the treatment group.
#   ctrl_sigma = 1, # Standard deviation for the non-zero g-scores in the control group.
#   ctrl_h_sigma = 1, # Standard deviation for the non-zero g-scores in the historical control group.
#   stringsAsFactors = FALSE
# ) %>%
#   filter(trt_n == ctrl_n, trt_prob >= ctrl_prob)
# 
# data_gen_params_list <- lapply(apply(param_grid, 1, as.list), 
#                                create_data_gen_params, endpoint = "g-score")
# prior_params_list <- list(
#   Yes = list(control.delta = log(0.85), treatment.w = 0, control.w = NULL),
#   No = list(treatment.w = 0, control.w = 0)
# )
# 
# ## Run simulations
# log_file <- "simulation_gscore_log_7_12.txt"
# sink(log_file, append = F, split = FALSE)
# 
# nsim = 1000
# all_results <- lapply(seq_along(data_gen_params_list), function(i) {
#   data_gen_params <- data_gen_params_list[[i]]
#   cat("Running", nsim, "simulations for data_gen_params set", i, "\n\n")
#   for (arm in names(data_gen_params)) {
#     cat("\t Arm:", arm, "\n")
#     cat("\t  n:", data_gen_params[[arm]]$n, "\n")
#     cat("\t  prob:", data_gen_params[[arm]]$prob, "\n")
#     cat("\t  mu:", data_gen_params[[arm]]$mu, "\n")
#     cat("\t  sigma:", data_gen_params[[arm]]$sigma, "\n\n")
#   }
#   t <- system.time({
#     results <- run_simulation(endpoint = "g-score", nsim = nsim, 
#                               data_gen_params = data_gen_params, 
#                               prior_params_list = prior_params_list,
#                               lrv = 0.8, tv = 0.5, fgr = 0.2, fsr = 0.1, posterior_infer = T,
#                               Lalonde_decision = T)
#   })
#   cat("Elapsed time:", t["elapsed"], "seconds\n")
#   cat("=======================================================\n\n")
#   return(results)
# })
# 
# while (sink.number() > 0) {
#   sink(NULL)
# }
# 
# combined_post_params <- do.call(rbind, lapply(all_results, function(res) res$post_params))
# saveRDS(combined_post_params, file = "sim_rslt_gscore_post_params_7_11.rds")
# 
# combined_post_params <- readRDS("sim_rslt_gscore_post_params_7_11.rds")
# 
# 
# # 7/17/2024: small sample sizes and high proportion of zeros
# param_grid <- expand.grid(
#   trt_n = seq(15,40, 5), # Sample size for the treatment group.
#   ctrl_n = seq(15,40, 5), # Sample size for the control group.
#   trt_prob = seq(0.05, 0.45, 0.1), # Probability of zero g-scores in the treatment group.
#   ctrl_prob = seq(0, 0.4, 0.1), # Probability of zero g-scores in the control group.
#   trt_mu = 0.007, # Mean for the non-zero g-scores in the treatment group.
#   ctrl_mu = 0.01, # Mean for the non-zero g-scores in the control group.
#   trt_sigma = 1, # Standard deviation for the non-zero g-scores in the treatment group.
#   ctrl_sigma = 1, # Standard deviation for the non-zero g-scores in the control group.
#   stringsAsFactors = FALSE
# ) %>%
#   filter(trt_n == ctrl_n, trt_prob == ctrl_prob + 0.05)
# 
# data_gen_params_list <- lapply(apply(param_grid, 1, as.list),
#                                create_data_gen_params, endpoint = "g-score")
# 
# ## Run simulations
# log_file <- "simulation_gscore_dist_log.txt"
# sink(log_file, append = TRUE, split = FALSE)
# 
# nsim = 10000
# all_results <- lapply(seq_along(data_gen_params_list), function(i) {
#   data_gen_params <- data_gen_params_list[[i]]
#   cat("Running", nsim, "simulations for data_gen_params set", i, "\n\n")
#   for (arm in names(data_gen_params)) {
#     cat("\t Arm:", arm, "\n")
#     cat("\t  n:", data_gen_params[[arm]]$n, "\n")
#     cat("\t  prob:", data_gen_params[[arm]]$prob, "\n")
#     cat("\t  mu:", data_gen_params[[arm]]$mu, "\n")
#     cat("\t  sigma:", data_gen_params[[arm]]$sigma, "\n\n")
#   }
#   t <- system.time({
#     results <- run_simulation_gscore_distribution(endpoint = "g-score", nsim = nsim,
#                               data_gen_params = data_gen_params)
#     results <- run_simulation(endpoint = "g-score", nsim = nsim,
#                               data_gen_params = data_gen_params, posterior_infer = F)
#   })
#   cat("Elapsed time:", t["elapsed"], "seconds\n")
#   cat("=======================================================\n\n")
#   return(results)
# })
# 
# while (sink.number() > 0) {
#   sink(NULL)
# }
# 
# combined_metrics <- do.call(rbind, lapply(all_results, function(res) res$metrics))
# combined_data_gen_params <- do.call(rbind, lapply(data_gen_params_list, function(res) cbind(as.data.frame(res$treatment), as.data.frame(res$control))))
# colnames(combined_data_gen_params) <- paste0(rep(c("treatment.", "control."), each = 5), c("n", "prob", "mu", "sigma", "name"))
# combined_metrics <- cbind(combined_data_gen_params, combined_metrics)
# 
# saveRDS(combined_metrics, file = "gscore_dist_check_metrics_7_17.rds")
# 
# 
# 
# # 7/24/2024: small sample sizes and high proportion of zeros
# param_grid1 <- expand.grid(
#   trt_n = c(50, 100, 150, 200, 250, 300, 350, 400), # Sample size for the treatment group.
#   ctrl_n = c(50, 100, 150, 200, 250, 300, 350, 400), # Sample size for the control group.
#   trt_prob = 0.45, # Probability of zero g-scores in the treatment group.
#   ctrl_prob = 0.4, # Probability of zero g-scores in the control group.
#   trt_mu = 0.0018, # Mean for the non-zero g-scores in the treatment group.
#   ctrl_mu = 0.003, # Mean for the non-zero g-scores in the control group.
#   trt_sigma = 1, # Standard deviation for the non-zero g-scores in the treatment group.
#   ctrl_sigma = 1, # Standard deviation for the non-zero g-scores in the control group.
#   stringsAsFactors = FALSE
# ) %>%
#   filter(trt_n == ctrl_n, trt_prob == ctrl_prob + 0.05)
# 
# param_grid2 <- expand.grid(
#   trt_n = seq(15,40, 5), # Sample size for the treatment group.
#   ctrl_n = seq(15,40, 5), # Sample size for the control group.
#   trt_prob = seq(0.05, 0.45, 0.1), # Probability of zero g-scores in the treatment group.
#   ctrl_prob = seq(0, 0.4, 0.1), # Probability of zero g-scores in the control group.
#   trt_mu = 0.0018, # Mean for the non-zero g-scores in the treatment group.
#   ctrl_mu = 0.003, # Mean for the non-zero g-scores in the control group.
#   trt_sigma = 1, # Standard deviation for the non-zero g-scores in the treatment group.
#   ctrl_sigma = 1, # Standard deviation for the non-zero g-scores in the control group.
#   stringsAsFactors = FALSE
# ) %>%
#   filter(trt_n == ctrl_n, trt_prob == ctrl_prob + 0.05)
# 
# 
# param_grid <- rbind(param_grid2, param_grid1)
# data_gen_params_list <- lapply(apply(param_grid, 1, as.list),
#                                create_data_gen_params, endpoint = "g-score")
# 
# ## Run simulations
# log_file <- "simulation_gscore_dist_log.txt"
# sink(log_file, append = TRUE, split = FALSE)
# 
# nsim = 10000
# all_results <- lapply(seq_along(data_gen_params_list), function(i) {
#   data_gen_params <- data_gen_params_list[[i]]
#   cat("Running", nsim, "simulations for data_gen_params set", i, "\n\n")
#   for (arm in names(data_gen_params)) {
#     cat("\t Arm:", arm, "\n")
#     cat("\t  n:", data_gen_params[[arm]]$n, "\n")
#     cat("\t  prob:", data_gen_params[[arm]]$prob, "\n")
#     cat("\t  mu:", data_gen_params[[arm]]$mu, "\n")
#     cat("\t  sigma:", data_gen_params[[arm]]$sigma, "\n\n")
#   }
#   t <- system.time({
#     results <- run_simulation(endpoint = "g-score", nsim = nsim,
#                               data_gen_params = data_gen_params, historical_borrowing = F)
#   })
#   cat("Elapsed time:", t["elapsed"], "seconds\n")
#   cat("=======================================================\n\n")
#   return(results)
# })
# 
# while (sink.number() > 0) {
#   sink(NULL)
# }
# 
# combined_metrics1 <- do.call(rbind, lapply(all_results, function(res) res$metrics))
# combined_metrics_approx_dist <- do.call(rbind, lapply(all_results, function(res) res$metrics_approx_dist ))
# colnames(combined_data_gen_params1) <- paste0(rep(c("treatment.", "control."), each = 5), c("n", "prob", "mu", "sigma", "name"))
# combined_metrics1 <- cbind(combined_data_gen_params1, combined_metrics1)
# 
# saveRDS(all_results, file = "gscore_dist_check_all_results_7_26_0.0018_0.003.rds")
# saveRDS(combined_metrics1, file = "gscore_dist_check_metrics_7_26_0.0018_0.003.rds")
# 
# 
# 
# 
# # 7/24/2024: small sample sizes and high proportion of zeros
# param_grid1 <- expand.grid(
#   trt_n = c(50, 100, 150, 200, 250, 300, 350, 400), # Sample size for the treatment group.
#   ctrl_n = c(50, 100, 150, 200, 250, 300, 350, 400), # Sample size for the control group.
#   trt_prob = 0.45, # Probability of zero g-scores in the treatment group.
#   ctrl_prob = 0.4, # Probability of zero g-scores in the control group.
#   trt_mu = 0.007, # Mean for the non-zero g-scores in the treatment group.
#   ctrl_mu = 0.01, # Mean for the non-zero g-scores in the control group.
#   trt_sigma = 1, # Standard deviation for the non-zero g-scores in the treatment group.
#   ctrl_sigma = 1, # Standard deviation for the non-zero g-scores in the control group.
#   stringsAsFactors = FALSE
# ) %>%
#   filter(trt_n == ctrl_n, trt_prob == ctrl_prob + 0.05)
# 
# param_grid2 <- expand.grid(
#   trt_n = seq(15,40, 5), # Sample size for the treatment group.
#   ctrl_n = seq(15,40, 5), # Sample size for the control group.
#   trt_prob = seq(0.05, 0.45, 0.1), # Probability of zero g-scores in the treatment group.
#   ctrl_prob = seq(0, 0.4, 0.1), # Probability of zero g-scores in the control group.
#   trt_mu = 0.007, # Mean for the non-zero g-scores in the treatment group.
#   ctrl_mu = 0.01, # Mean for the non-zero g-scores in the control group.
#   trt_sigma = 1, # Standard deviation for the non-zero g-scores in the treatment group.
#   ctrl_sigma = 1, # Standard deviation for the non-zero g-scores in the control group.
#   stringsAsFactors = FALSE
# ) %>%
#   filter(trt_n == ctrl_n, trt_prob == ctrl_prob + 0.05)
# 
# 
# param_grid <- rbind(param_grid2, param_grid1)
# data_gen_params_list <- lapply(apply(param_grid, 1, as.list),
#                                create_data_gen_params, endpoint = "g-score")
# 
# ## Run simulations
# log_file <- "simulation_gscore_dist_log.txt"
# sink(log_file, append = TRUE, split = FALSE)
# 
# nsim = 10000
# all_results <- lapply(seq_along(data_gen_params_list), function(i) {
#   data_gen_params <- data_gen_params_list[[i]]
#   cat("Running", nsim, "simulations for data_gen_params set", i, "\n\n")
#   for (arm in names(data_gen_params)) {
#     cat("\t Arm:", arm, "\n")
#     cat("\t  n:", data_gen_params[[arm]]$n, "\n")
#     cat("\t  prob:", data_gen_params[[arm]]$prob, "\n")
#     cat("\t  mu:", data_gen_params[[arm]]$mu, "\n")
#     cat("\t  sigma:", data_gen_params[[arm]]$sigma, "\n\n")
#   }
#   t <- system.time({
#     results <- run_simulation_gscore_distribution(endpoint = "g-score", nsim = nsim,
#                                                   data_gen_params = data_gen_params)
#   })
#   cat("Elapsed time:", t["elapsed"], "seconds\n")
#   cat("=======================================================\n\n")
#   return(results)
# })
# 
# 
# 
# combined_metrics1 <- do.call(rbind, lapply(all_results, function(res) res$metrics))
# combined_data_gen_params1 <- do.call(rbind, lapply(data_gen_params_list, function(res) cbind(as.data.frame(res$treatment), as.data.frame(res$control))))
# colnames(combined_data_gen_params1) <- paste0(rep(c("treatment.", "control."), each = 5), c("n", "prob", "mu", "sigma", "name"))
# combined_metrics1 <- cbind(combined_data_gen_params1, combined_metrics1)
# 
# saveRDS(all_results, file = "gscore_dist_check_all_results_7_26_0.007_0.01.rds")
# saveRDS(combined_metrics1, file = "gscore_dist_check_metrics_7_26_0.007_0.01.rds")
# 
# combined_metrics <- readRDS("gscore_dist_check_metrics_7_26_0.007_0.01.rds")
# 
# metrics_df <- combined_metrics %>%
#   select(treatment.prob, control.prob, delta, treatment.n, bias_avg_median_ratio, sd_avg, sd_empirical, cp) %>%
#   mutate(delta = exp(delta)) %>% 
#   arrange(treatment.prob, treatment.n)
# 
# kbl(metrics_df, escape = F, format = "html",
#     col.names = c("Treatment", "Control", "True Median Ratio\n(Treatment/Control)<sup>1</sup>", "Sample Size<sup>2</sup>", "BIAS<sup>3</sup>", "SE<sup>4</sup>", "SD<sup>5</sup>", "CP<sup>6</sup>")) %>%
#   kable_classic(full_width = FALSE, position = "float_right", font_size = 9) %>%
#   add_header_above(c("Prob of Zero" = 2, " " = 6)) %>%
#   collapse_rows(columns = 1:3, valign = "top") %>%
#   footnote(number = c("True g-score median of treatment arm over true g-score median of control arm, obtained based on the zero-inflated lognormal distribution (determined by proportion of zeros in both arms)",
#                       "Sample size for each arm.",
#                       "Average bias of the estimated median ratio over 10K simulations.",
#                       "Average standard error of the estimated log median ratio over 10K simulations.",
#                       "Empirical standard deviation of the estimated log median ratio.",
#                       "95% coverage probability under normal distribution."))
#   
# 
# 
# metrics_long <- metrics_df %>%
#   pivot_longer(c(bias_avg, bias_relative), names_to = "bias_type", values_to = "bias_value")
# 
# 
# p1 <- ggplot(metrics_long, aes(x = treatment.n, y = bias_value, color = bias_type)) +
#   geom_point() +
#   facet_wrap(~treatment.prob + control.prob, labeller = label_both, nrow = 1) +
#   geom_hline(yintercept = 0, color = "red", linetype = "dashed") +
#   labs(x = "Sample Size", y = "Bias", title = "Bias") +
#   theme_bw() +
#   theme(legend.position = "bottom")
# 
# 
# p1 <- ggplot(metrics_df, aes(x = treatment.n, y = bias_avg)) +
#   geom_point() +
#   facet_wrap(~treatment.prob + control.prob, labeller = label_both, nrow = 1) +
#   geom_hline(yintercept = 0, color = "red", linetype = "dashed") +
#   labs(x = "Sample Size", y = "Bias", title = "Average Bias") +
#   theme_bw()
# 
# p11 <- ggplot(metrics_df, aes(x = treatment.n, y = bias_relative)) +
#   geom_point() +
#   facet_wrap(~treatment.prob + control.prob, labeller = label_both, nrow = 1) +
#   geom_hline(yintercept = 0, color = "red", linetype = "dashed") +
#   labs(x = "Sample Size", y = "Bias", title = "Relative Bias") +
#   theme_bw()
# 
# metrics_long <- metrics_df %>%
#   pivot_longer(c(sd_avg, sd_empirical), names_to = "sd_type", values_to = "sd_value")
# 
# p2 <- ggplot(metrics_long, aes(x = treatment.n, y = sd_value, color = sd_type)) +
#   geom_point() +
#   facet_wrap(~treatment.prob + control.prob, labeller = label_both, nrow = 1) +
#   labs(x = "Sample Size", y = "SD", title = "Average SD vs. Empirical SD") +
#   theme_bw() +
#   theme(legend.position = "bottom")
# 
# p3 <-  ggplot(metrics_df, aes(x = treatment.n, y = cp)) +
#   geom_point() +
#   facet_wrap(~treatment.prob + control.prob, labeller = label_both, nrow = 1) +
#   geom_hline(yintercept = 0.95, color = "red", linetype = "dashed") +
#   labs(x = "Sample Size", y = "Coverage probability", title = "Coverage Probability") +
#   theme_bw()
# 
# p <- p1 / p2 / p3
# 
# ggsave(filename = "gscore_dist_check_metrics_7_17.jpg", p, width = 8, height = 8)



# #  Run Simulations - g-score ----------------------------------------------
# 
# 7/24/2024
param_grid <- expand.grid(
  trt_n = seq(10, 40, 5), # Sample size for the treatment group.
  ctrl_n = seq(10, 40, 5), # Sample size for the control group.
  ctrl_h_n = 200, # Sample size for the historical control group.
  trt_prob = c(0.1, 0.15), # Probability of zero g-scores in the treatment group.
  ctrl_prob = 0.1, # Probability of zero g-scores in the control group.
  ctrl_h_prob = c(0.1, 0.15), # Probability of zero g-scores in the historical control group.
  trt_mu = c(0.005, 0.008), # Mean for the non-zero g-scores in the treatment group.
  ctrl_mu = 0.01, # Mean for the non-zero g-scores in the control group.
  ctrl_h_mu = c(0.01 / seq(0.75, 0.95, 0.1), 0.01, 0.01 * seq(0.75, 0.95, 0.1)),
  trt_sigma = 1, # Standard deviation for the non-zero g-scores in the treatment group.
  ctrl_sigma = 1, # Standard deviation for the non-zero g-scores in the control group.
  ctrl_h_sigma = 1, # Standard deviation for the non-zero g-scores in the historical control group.
  stringsAsFactors = FALSE
) %>%
  filter(trt_n == ctrl_n)

data_gen_params_list <- lapply(apply(param_grid, 1, as.list),
                               create_data_gen_params, endpoint = "g-score")

prior_params_list <- list(
  control = list(treatment.delta = log(0.85), control.delta = log(0.85), treatment.w = 0, control.w = NULL), # borrowing for the control arm
  neither = list(treatment.delta = log(0.85), control.delta = log(0.85), treatment.w = 0, control.w = 0) # no borrowing
)
# 
# ## Run simulations
# log_file <- "simulation_gscore_log_7_18.txt"
# sink(log_file, append = TRUE, split = FALSE)
# 
# nsim = 10000
# all_results <- lapply(seq_along(data_gen_params_list), function(i) {
#   data_gen_params <- data_gen_params_list[[i]]
#   cat("Running", nsim, "simulations for data_gen_params set", i, "\n\n")
#   for (arm in names(data_gen_params)) {
#     cat("\t Arm:", arm, "\n")
#     cat("\t  n:", data_gen_params[[arm]]$n, "\n")
#     cat("\t  prob:", data_gen_params[[arm]]$prob, "\n")
#     cat("\t  mu:", data_gen_params[[arm]]$mu, "\n")
#     cat("\t  sigma:", data_gen_params[[arm]]$sigma, "\n\n")
#   }
#   t <- system.time({
#     results <- run_simulation(endpoint = "g-score", nsim = nsim, 
#                               data_gen_params = data_gen_params, 
#                               prior_params_list = prior_params_list,
#                               lrv = 0.8, tv = 0.5, fgr = 0.2, fsr = 0.1)
#   })
#   cat("Elapsed time:", t["elapsed"], "seconds\n")
#   cat("=======================================================\n\n")
#   return(results)
# })
# 
# while (sink.number() > 0) {
#   sink(NULL)
# }
# 
# ## Save the posterior parameters, decisions for each run, and OC for each setting
# combined_decisions <- do.call(rbind, lapply(seq_along(all_results), function(i) {
#   res <- all_results[[i]]
#   res$decisions$data_gen_setting <- i
#   return(res$decisions)
# }))
# 
# combined_OC <- do.call(rbind, lapply(seq_along(all_results), function(i) {
#   res <- all_results[[i]]
#   res$OC$data_gen_setting <- i
#   return(res$OC)
# }))
# 
# combined_post_params <- do.call(rbind, lapply(seq_along(all_results), function(i) {
#   res <- all_results[[i]]
#   res$post_params$data_gen_setting <- i
#   return(res$post_params)
# }))
# 
# combined_median_est <- do.call(rbind, lapply(seq_along(all_results), function(i) {
#   res <- all_results[[i]]
#   res$median_est$data_gen_setting <- i
#   return(res$median_est)
# }))
# 
# combined_metrics_approx_dist <- do.call(rbind, lapply(seq_along(all_results), function(i) {
#   res <- all_results[[i]]
#   res$metrics_approx_dist$data_gen_setting <- i
#   return(res$metrics_approx_dist)
# }))
# 
# saveRDS(all_results, file = "sim_rslt_gscore_all_results_7_24.rds")
# saveRDS(combined_post_params, file = "sim_rslt_gscore_post_params_7_24.rds")
# saveRDS(combined_decisions, file = "sim_rslt_gscore_decisions_7_24.rds")
# saveRDS(combined_OC, file = "sim_rslt_gscore_oc_7_24.rds")
# saveRDS(combined_median_est, file = "sim_rslt_gscore_median_est_7_24.rds")
# saveRDS(combined_metrics_approx_dist, file = "sim_rslt_gscore_metrics_approx_dist_7_24.rds")



combined_post_params <- readRDS("sim_rslt_gscore_post_params_7_24.rds")
combined_decisions <- readRDS("sim_rslt_gscore_decisions_7_24.rds")
combined_OC <- readRDS("sim_rslt_gscore_oc_7_24.rds")
combined_median_est <- readRDS("sim_rslt_gscore_median_est_7_24.rds")
combined_metrics_approx_dist <- readRDS("sim_rslt_gscore_metrics_approx_dist_7_24.rds")







# all_results <- readRDS("sim_rslt_gscore_all_results_7_24.rds")
# ## Check posterior parameters
post_param <- combined_post_params <- readRDS("sim_rslt_gscore_post_params_7_24.rds")
median_est <- combined_median_est <- readRDS("sim_rslt_gscore_median_est_7_24.rds")
# 
# 
post_param <- post_param[, c("borrowing", "data_gen_setting", colnames(post_param)[startsWith(colnames(post_param), "control")])]
# ess_summary <- post_param %>%
#   group_by(data_gen_setting, borrowing) %>%
#   summarise(ess_mean = mean(control.ess_post),
#             ess_sd = sd(control.ess_post),
#             degree_mean = mean(control.borrowing_degree),
#             degree_sd = sd(control.borrowing_degree))
# 
# ggplot(ess_summary, aes(x = data_gen_setting, y = ess_mean, color = borrowing)) +
#   geom_point() +
#   labs(title = "Average effective sample size over 1K simulations for each data generating setting.") +
#   theme_bw()
# 
# ggplot(ess_summary, aes(x = data_gen_setting, y = degree_mean, color = borrowing)) +
#   geom_point() +
#   labs(title = "Average degree of borrowing over 1K simulations for each data generating setting.") +
#   theme_bw()
# 
# nrow(post_param[post_param$data_gen_setting ==1,])
# 
# 
post_param$settings <- rep(1:length(data_gen_params_list), each = (length(prior_params_list) * nsim))
median_est$settings <- rep(1:length(data_gen_params_list), each = (length(data_gen_params_list[[1]])* nsim))
# 
# post_param$nsim <- rep(1:nsim, (length(prior_params_list)*length(data_gen_params_list)))
#   
# post_param$control.mu <- as.numeric(post_param$control.mu)
# post_param$control_h.mu <- as.numeric(post_param$control_h.mu)
# post_param$control.mu.logdiff <- as.character(round(exp(post_param$control.mu - post_param$control_h.mu), 2))
# 
# 
# for (i in 1:nrow(post_param)) {
#   post_i <- post_param[i,]
#   params_i <- post_i[, startsWith(colnames(post_i), "control.") & endsWith(colnames(post_i), "_post")]
#   sampling_i <- median_est[median_est$settings == post_i$settings & median_est$arm == "control" & median_est$nsim == post_i$nsim, ]
#   # var(mu_hat) = V_ZH / theta_hat^2
#   sigma_i = ( sampling_i$median_sd / sampling_i$median_adjusted ) * sqrt(sampling_i$n)
#   
#   # Obtain ESS
#   post <- convert_RBesT_mix(post = params_i, endpoint = "g-score")
#   ess_post <- ess(post, sigma = sigma_i)
#   
#   post_param[i, "ess_post"] <- ess_post
# }
# 
# ggplot(post_param, aes(x = control.mu.logdiff, y = control.w_post, color = control.prob)) +
#   geom_boxplot(width = 0.6, outlier.size = 0.6, outlier.alpha = 0.5) +
#   facet_wrap(~control.n, labeller = label_both, nrow = 1) +
#   labs(x = "Ratio of the mean of g-score > 0 comparing current to historical control",
#        y = "Posterior weight of borrowing",
#        color = "Prob of g-score = 0 in current control",
#        title = "Mean of g-score > 0 in current control = 0.01, delta for SAM = log(0.85)") +
#   theme_bw() +
#   theme(legend.position = "bottom", strip.text.x = element_text(size=10))
# 
# ggsave("prior_data_conflict_weights_gscore_7_18.jpg", width = 12, height = 3.5)
# 
# 
# 
# post_param <- combined_post_params[combined_post_params$control.prob == "0.1", ]
# post_params <- post_param[1, c("control.w1_post", "control.mu1_post", "control.sigma1_post", "control.mu2_post", "control.sigma2_post")]
# names(post_params)[1] <- "control.w_post"
# 
# df <- readRDS("sim_rslt_gscore_decisions_7_8.rds")
# 
# 
# ## Check the OC
# combined_OC <- readRDS("sim_rslt_gscore_oc_7_8.rds")
oc <- combined_OC[combined_OC$control.prob == combined_OC$control_h.prob, c("true_value", "control.n", "borrowing",
                      "treatment.prob", "treatment.mu", "control.prob", "control.mu", 
                      "control_h.prob", "control_h.mu",
                      "decision_pr", "proportion_pr")]

oc$decision_pr <- factor(oc$decision_pr, levels = c("no-go", "consider", "go"))
oc$borrowing = ifelse(oc$borrowing == "neither", "No",
                      ifelse(oc$borrowing == "control", "Yes", oc$borrowing))
oc$true_value <- round(as.numeric(oc$true_value),2)
oc$true_value = ifelse(oc$true_value == 0.5, "0.5 (TV)",
                       ifelse(oc$true_value == 0.8, "0.8 (LRV)", oc$true_value))

oc$control.mu <- as.numeric(oc$control.mu)
oc$control_h.mu <- as.numeric(oc$control_h.mu)
oc$control.mu.logdiff <- as.character(round(exp(oc$control.mu - oc$control_h.mu), 2))
oc$control.mu.diff <- paste0("log(", as.character(oc$control.mu.logdiff), ")")

metrics <- oc[oc$true_value %in% c("0.5 (TV)", "0.8 (LRV)"),]
metrics <- oc[(oc$true_value == "0.8 (LRV)" & oc$decision_pr == "go") | (oc$true_value == "0.5 (TV)" & oc$decision_pr == "no-go"),]

false_go_risk <- metrics[metrics$true_value == "0.8 (LRV)", c("control.n", "borrowing", "proportion_pr", "control.mu.logdiff")]
colnames(false_go_risk)[3] <- "false_go_risk"
false_stop_risk <- metrics[metrics$true_value == "0.5 (TV)", c("control.n", "borrowing", "proportion_pr", "control.mu.logdiff")]
colnames(false_stop_risk)[3] <- "false_stop_risk"
metrics_df <- merge(false_go_risk, false_stop_risk, by = c("control.n", "borrowing", "control.mu.logdiff"))
metrics_long <- melt(metrics_df, id.vars = c("control.n", "borrowing", "control.mu.logdiff"),
                     measure.vars = c("false_go_risk", "false_stop_risk"),
                     variable.name = "risk_type", value.name = "risk_value")

ggplot(metrics_long[metrics_long$borrowing == "Yes",], aes(x = control.mu.logdiff, y = risk_value, color = risk_type)) +
  geom_point() +
  facet_wrap(~ control.n, labeller = label_both, nrow = 1) +
  labs(title = "False Go Risk and False Stop Risk vs. Prior-data Conflict",
       x = "Ratio of the mean of g-score > 0 comparing current to historical control",
       y = "Risk Value",
       color = "Risk Type") +
  geom_hline(aes(yintercept = 0.2, color = "false_go_risk"), linetype = "dashed") +  # Horizontal line for false go risk
  geom_hline(aes(yintercept = 0.1, color = "false_stop_risk"), linetype = "dashed") +
  theme_bw()+
  theme(legend.position = "bottom", strip.text.x = element_text(size = 10))
ggsave("prior_data_conflict_risk_gscore_final.jpg", width = 14, height = 3.5)


oc_new <- data.frame()
for (i in seq(1, nrow(oc), 3)) {
  tmp <- oc[i:(i+2),]
  tmp[tmp$decision_pr == "go", "label_ypos"] <- tmp[tmp$decision_pr == "go", "proportion_pr"]
  tmp[tmp$decision_pr == "consider", "label_ypos"] <- tmp[tmp$decision_pr == "go", "proportion_pr"] + tmp[tmp$decision_pr == "consider", "proportion_pr"]
  tmp[tmp$decision_pr == "no-go", "label_ypos"] <- 1
  oc_new <- rbind(oc_new, tmp)
}

oc_new <- oc_new[oc_new$control.mu.logdiff == "1", c("true_value", "control.n", "borrowing", "control.prob", "control.mu.logdiff",
                                                     "decision_pr", "proportion_pr", "label_ypos")]

myColors <- c("red","#F0E442","#009E73")
names(myColors) <- levels(oc_new$decision_pr)

ggplot(oc_new, aes(x = control.n, y = proportion_pr, fill = decision_pr)) +
  geom_bar(stat = "identity", width = 1) +
  geom_hline(yintercept = c(0.2, 0.9), linetype = "dashed") +
  scale_fill_manual(name = "Decision", values = myColors)+
  facet_grid(borrowing~true_value, labeller = label_both) +
  labs(title = "Probability of Each Decision Under Various Sample Sizes (No Prior-data Conflict)", x = "Number of Patients", y = "Probability") +
  theme(legend.position = "bottom",
        title = element_text(size = 14),
        legend.text = element_text(size = 10),
        strip.text = element_text(size = 12))

ggsave("sample_size_all_borrowing_gscore_7_8.jpg", width = 22, height = 6)

lines <- data.frame(true_value = c("0.5 (TV)", "0.8 (LRV)"),
                    Z = c(0.9, 0.2))
ggplot(oc_new[oc_new$true_value %in% c("0.5 (TV)", "0.8 (LRV)"), ],
       aes(x = control.n, y = proportion_pr, fill = decision_pr)) +
  geom_bar(stat = "identity") +
  geom_text(aes(y = label_ypos, label = scales::percent(proportion_pr, 0.1)), vjust = 1.6,
            size = 3) +
  scale_fill_manual(name = "Decision", values = myColors)+
  facet_grid(borrowing~true_value,
             labeller = label_both) +
  geom_hline(data = lines, aes(yintercept = Z), linetype = "dashed") +
  labs(title = "Probability of Each Decision Under Various Sample Sizes (No Prior-data Conflict)", x = "Number of Patients", y = "Probability") +
  # scale_x_discrete(breaks=seq(15,40,3)) +
  theme(legend.position = "bottom",
        title = element_text(size = 14),
        legend.text = element_text(size = 10),
        strip.text = element_text(size = 13))

ggsave("sample_size_threshold_gscore_final.jpg", width = 12, height = 5)

# 
# oc1 <- oc_new %>%
#   filter(borrowing %in% c("No", "Yes") & control.n == "40")
# 
# ggplot(oc1, aes(x = true_value, y = proportion_pr, fill = decision_pr)) +
#   geom_bar(stat = "identity") +
#   geom_hline(yintercept = c(0.2, 0.9), linetype = "dashed") +
#   # geom_text(aes(label = scales::percent(proportion_pr)), vjust = 1.6, color = "black") +
#   scale_fill_manual(name = "Decision", values = myColors)+
#   facet_grid(~borrowing,
#              labeller = labeller(borrowing = c("No" = "No borrowing",
#                                                "Yes" = "Borrowing for control"))) +
#   labs(title = "Probability of Each Decision Under Sample Size = 40 with No Prior-data Conflict", x = "True Median Ratio", y = "Probability") +
#   theme(title = element_text(size = 12),
#         legend.text = element_text(size = 9),
#         strip.text = element_text(size = 10)) +
#   scale_y_continuous(breaks = seq(0,1, 0.1))
# ggsave("OC_n40_gscore_7_8.jpg", width = 8, height = 4)
# 
# 
# oc2 <- oc_new %>%
#   select(-c(label_ypos, control.prob, control.mu.logdiff)) %>%
#   filter(true_value %in% c("0.5 (TV)", "0.8 (LRV)")) %>%
#   mutate(proportion_pr = scales::percent(proportion_pr, 0.1)) %>%
#   arrange(decision_pr) %>%
#   arrange(true_value) %>%
#   arrange(borrowing) %>%
#   pivot_wider(names_from = c(decision_pr, borrowing), values_from = proportion_pr) %>%
#   arrange(control.n)
# 
# oc2$`no-go_No` = cell_spec(oc2$`no-go_No`,
#                            background = ifelse(oc2$true_value == "0.5 (TV)", "steelblue2", "white"))
# 
# oc2$`no-go_Yes` = cell_spec(oc2$`no-go_Yes`,
#                             background = ifelse(oc2$true_value == "0.5 (TV)", "steelblue2", "white"))
# 
# oc2$`go_No` = cell_spec(oc2$`go_No`,
#                         background = ifelse(oc2$true_value == "0.8 (LRV)", "pink", "white"))
# 
# oc2$`go_Yes` = cell_spec(oc2$`go_Yes`,
#                          background = ifelse(oc2$true_value == "0.8 (LRV)", "pink", "white"))
# 
# kbl(oc2[, c(2,1,3:ncol(oc2))], escape = F,
#     col.names = c("Sample Size", "True value",rep(c("No-Go", "Consider","Go"), 2))) %>%
#   kable_classic(full_width = FALSE) %>%
#   add_header_above(c(" " = 2, "No Borrowing" = 3, "Borrowing (Control)" = 3)) %>%
#   column_spec(1, bold = T) %>%
#   collapse_rows(columns = 1:2, valign = "top")
# 
# 
# 





# Check dat ---------------------------------------------------------------

param_grid <- expand.grid(
  trt_n = c(seq(15,40,5), c(50, 100, 150, 200, 250, 300, 350, 400)), # Sample size for the treatment group.
  ctrl_n = c(seq(15,40,5), c(50, 100, 150, 200, 250, 300, 350, 400)), # Sample size for the control group.
  trt_prob = seq(0.05, 0.45, 0.1), # Probability of zero g-scores in the treatment group.
  ctrl_prob = seq(0, 0.4, 0.1), # Probability of zero g-scores in the control group.
  trt_mu = c(0.0018,0.007), # Mean for the non-zero g-scores in the treatment group.
  ctrl_mu = c(0.003,0.01), # Mean for the non-zero g-scores in the control group.
  trt_sigma = 1, # Standard deviation for the non-zero g-scores in the treatment group.
  ctrl_sigma = 1, # Standard deviation for the non-zero g-scores in the control group.
  stringsAsFactors = FALSE
) %>%
  filter(trt_n == ctrl_n, 
         trt_prob == ctrl_prob + 0.05,
         (trt_mu == 0.0018 & ctrl_mu == 0.003) | 
           (trt_mu == 0.007 & ctrl_mu == 0.01))

param_grid2 <- expand.grid(
  trt_n =  c(50, 100, 150, 200, 250, 300, 350, 400), # Sample size for the treatment group.
  ctrl_n = c(50, 100, 150, 200, 250, 300, 350, 400), # Sample size for the control group.
  trt_prob = 0.45, # Probability of zero g-scores in the treatment group.
  ctrl_prob = 0.4, # Probability of zero g-scores in the control group.
  trt_mu = c(0.0018,0.007), # Mean for the non-zero g-scores in the treatment group.
  ctrl_mu = c(0.003,0.01), # Mean for the non-zero g-scores in the control group.
  trt_sigma = 1, # Standard deviation for the non-zero g-scores in the treatment group.
  ctrl_sigma = 1, # Standard deviation for the non-zero g-scores in the control group.
  stringsAsFactors = FALSE
) %>%
  filter(trt_n == ctrl_n, 
         trt_prob == ctrl_prob + 0.05,
         (trt_mu == 0.0018 & ctrl_mu == 0.003) | 
           (trt_mu == 0.007 & ctrl_mu == 0.01))

data_gen_params_list <- lapply(apply(param_grid, 1, as.list),
                               create_data_gen_params, endpoint = "g-score")

## Run simulations
log_file <- "simulation_gscore_dist_log.txt"
sink(log_file, append = TRUE, split = FALSE)

nsim = 10000
all_results <- lapply(seq_along(data_gen_params_list), function(i) {
  data_gen_params <- data_gen_params_list[[i]]
  cat("Running", nsim, "simulations for data_gen_params set", i, "\n\n")
  for (arm in names(data_gen_params)) {
    cat("\t Arm:", arm, "\n")
    cat("\t  n:", data_gen_params[[arm]]$n, "\n")
    cat("\t  prob:", data_gen_params[[arm]]$prob, "\n")
    cat("\t  mu:", data_gen_params[[arm]]$mu, "\n")
    cat("\t  sigma:", data_gen_params[[arm]]$sigma, "\n\n")
  }
  t <- system.time({
    results <- run_simulation(endpoint = "g-score", nsim = nsim,
                              data_gen_params = data_gen_params, historical_borrowing = F)
  })
  cat("Elapsed time:", t["elapsed"], "seconds\n")
  cat("=======================================================\n\n")
  return(results)
})

while (sink.number() > 0) {
  sink(NULL)
}
combined_g_sd_intermediate <- do.call(rbind, lapply(seq_along(all_results), function(i) {
  res <- all_results[[i]]
  res$g_sd_intermediate$data_gen_setting <- i
  return(res$g_sd_intermediate)
}))

combined_median_est <- do.call(rbind, lapply(seq_along(all_results), function(i) {
  res <- all_results[[i]]
  res$median_est$data_gen_setting <- i
  return(res$median_est)
}))

combined_metrics_approx_dist <- do.call(rbind, lapply(seq_along(all_results), function(i) {
  res <- all_results[[i]]
  res$metrics_approx_dist$data_gen_setting <- i
  return(res$metrics_approx_dist)
}))

combined_data <- do.call(rbind, lapply(seq_along(all_results), function(i) {
  res <- all_results[[i]]
  res$data$data_gen_setting <- i
  return(res$data)
}))

saveRDS(all_results, file = "sim_rslt_gscore_all_results_7_29.rds")
saveRDS(combined_median_est, file = "sim_rslt_gscore_median_est_7_29.rds")
saveRDS(combined_metrics_approx_dist, file = "sim_rslt_gscore_metrics_approx_dist_7_29.rds")

combined_metrics_approx_dist <- readRDS("sim_rslt_gscore_metrics_approx_dist_7_29.rds")
combined_metrics_approx_dist$control.mu = round(exp(combined_metrics_approx_dist$control.mu), 3)
combined_metrics_approx_dist$treatment.mu = round(exp(combined_metrics_approx_dist$treatment.mu), 4)

metrics_df <- combined_metrics_approx_dist %>%
  select(treatment.mu, control.mu, treatment.prob, control.prob,true_value, treatment.n, bias_avg_median_ratio1, sd_avg, sd_empirical, cp) %>%
  arrange(treatment.mu, control.mu, treatment.prob, treatment.n)

kbl(metrics_df, escape = F, row.names = F, 
    format    = "html", 
    longtable = T, 
    booktabs  = T, 
    col.names = c("Treatment", "Control", "Treatment", "Control", "True Median Ratio\n(Treatment/Control)<sup>1</sup>", "Sample Size<sup>2</sup>", "BIAS<sup>3</sup>", "SE<sup>4</sup>", "SD<sup>5</sup>", "CP<sup>6</sup>")) %>%
  kable_classic(full_width = FALSE) %>%
  add_header_above(c("Mean of positive g-score median" = 2, "Prob of Zero" = 2, " " = 6)) %>%
  collapse_rows(columns = 1:5, valign = "top") %>%
  footnote(number = c("True g-score median of treatment arm over true g-score median of control arm, obtained based on the zero-inflated lognormal distribution (determined by proportion of zeros in both arms)",
                      "Sample size for each arm.",
                      "Average bias of the estimated median ratio over 10K simulations.",
                      "Average standard error of the estimated log median ratio over 10K simulations.",
                      "Empirical standard deviation of the estimated log median ratio.",
                      "95% coverage probability under normal distribution."))



p1 <- ggplot(metrics_df, aes(x = treatment.n, y = bias_avg_median_ratio1)) +
  geom_point() +
  facet_grid(treatment.mu+control.mu~treatment.prob + control.prob, labeller = label_both) +
  geom_hline(yintercept = 0, color = "red", linetype = "dashed") +
  labs(x = "Sample Size", y = "Bias", title = "Average Bias") +
  theme_bw()

metrics_long <- metrics_df %>%
  pivot_longer(c(sd_avg, sd_empirical), names_to = "sd_type", values_to = "sd_value")

p2 <- ggplot(metrics_long, aes(x = treatment.n, y = sd_value, color = sd_type)) +
  geom_point() +
  facet_grid(treatment.mu+control.mu~treatment.prob + control.prob, labeller = label_both) +
  labs(x = "Sample Size", y = "SD", title = "Average SD vs. Empirical SD") +
  theme_bw() +
  theme(legend.position = "bottom")

p3 <- ggplot(metrics_df, aes(x = treatment.n, y = cp)) +
  geom_point() +
  facet_grid(treatment.mu+control.mu~treatment.prob + control.prob, labeller = label_both) +
  geom_hline(yintercept = 0.95, color = "red", linetype = "dashed") +
  labs(x = "Sample Size", y = "Coverage probability", title = "Coverage Probability") +
  theme_bw()

p <- p1 / p2 / p3

ggsave(filename = "gscore_dist_check_metrics_7_29.jpg", p, width = 10, height = 16)

# 
# 
# 
# 
# 
# 
# 
# 
# 
# 
# 
# 
# data10 <- combined_data[combined_data$data_gen_setting == 10,]
# data80 <- combined_data[combined_data$data_gen_setting == 80,]
# summary(data10$g_score)
# summary(data80$g_score)
# 
# est10 <- combined_median_est[combined_median_est$data_gen_setting == 10,] %>%
#   pivot_longer()
# est80 <- combined_median_est[combined_median_est$data_gen_setting == 80,]
# 
# summary(est10$treatment.median_adjusted)
# summary(est80$treatment.median_adjusted)
# 
# summary(est10$treatment.median_sd)
# summary(est80$treatment.median_sd)
# 
# summary(est10$treatment.median_sd / est10$treatment.median_adjusted)
# summary(est80$treatment.median_sd / est80$treatment.median_adjusted)
# 
# intermediate10 <- combined_g_sd_intermediate[combined_g_sd_intermediate$data_gen_setting == 10,] %>%
#   select(arm, g1_intermediate, g2_intermediate, numerator_intermediate) %>%
#   mutate(nsim = rep(1:10000, each = 2))
# 
# intermediate80 <- combined_g_sd_intermediate[combined_g_sd_intermediate$data_gen_setting == 80,] %>%
#   select(arm, g1_intermediate, g2_intermediate, numerator_intermediate)  %>%
#   mutate(nsim = rep(1:10000, each = 2))
# 
# 
# 
# combined10_ctrl <- merge(est10, intermediate10[intermediate10$arm == "control", ], by = "nsim") %>%
#   select(nsim, control.median_adjusted,
#          control.median_sd) %>%
#   mutate(sd_log = control.median_sd/control.median_adjusted)
# combined80_ctrl <- merge(est80, intermediate80[intermediate10$arm == "control", ], by = "nsim") %>%
#   select(nsim, control.median_adjusted,
#          control.median_sd) %>%
#   mutate(sd_log = control.median_sd/control.median_adjusted)
# 
# 
# combined10_ctrl[1,] / combined80_ctrl[1,]
# 
# 
# eval_gscore_approx_dist <- function(median_est_wide){
#   
#   # Parameter of interest: delta = mu_t - mu_c = log(theta_t/theta_c)
#   true_median_ratio = unique(median_est_wide$true_value)
#   cat("True Median Ratio:", true_median_ratio, "\n")
#   delta = log(true_median_ratio)
#   cat("Delta:", delta, "\n")
#   
#   delta_hat = log(median_est_wide$treatment.median_adjusted) - log(median_est_wide$control.median_adjusted)
#   cat("Delta Hat:\n")
#   print(summary(delta_hat))
#   
#   # Average Bias of delta_hat
#   bias_avg <- mean(delta_hat - delta)
#   cat("Average Bias of Delta Hat:", bias_avg, "\n")
#   
#   bias_relative <- bias_avg/abs(delta)
#   cat("Relative Bias of Delta Hat:", bias_relative, "\n")
#   
#   # Average Bias of estimated median ratio
#   median_ratio_hat = median_est_wide$treatment.median_adjusted / median_est_wide$control.median_adjusted
#   cat("Median Ratio Hat:\n")
#   print(summary(median_ratio_hat))
#   
#   bias_avg_median_ratio = mean(median_ratio_hat - true_median_ratio)
#   cat("Average Bias of Median Ratio Hat:", bias_avg_median_ratio, "\n")
#   
#   # Average SD (i.e., SE) of delta_hat
#   # SD = sqrt(var(mu_t_hat) + var(mu_c_hat))
#   # var(mu_hat) = V_ZH / theta_hat^2
#   var_mu_hat_t = (median_est_wide$treatment.median_sd)^2 / ((median_est_wide$treatment.median_adjusted)^2)
#   cat("Variance of Mu Hat T:\n")
#   print(summary(var_mu_hat_t))
#   
#   var_mu_hat_c = (median_est_wide$control.median_sd)^2 / ((median_est_wide$control.median_adjusted)^2)
#   cat("Variance of Mu Hat C:\n")
#   print(summary(var_mu_hat_c))
#   
#   sds <- sqrt(var_mu_hat_t + var_mu_hat_c)
#   cat("Standard Deviations (SDS):\n")
#   print(summary(sds))
#   
#   sd_avg = mean(sds)
#   cat("Average Standard Deviation (SD Avg):", sd_avg, "\n")
#   
#   # Empirical SD of delta_hat
#   sd_empirical = sd(delta_hat)
#   cat("Empirical Standard Deviation of Delta Hat:", sd_empirical, "\n")
#   
#   # Coverage probability 95%
#   ci = data.frame(cil = delta_hat + qnorm(0.025) * sds,
#                   ciu = delta_hat + qnorm(0.975) * sds)
#   cat("Confidence Intervals (CI):\n")
#   print(summary(ci))
#   
#   ci$coverage = ifelse((ci$cil < delta & ci$ciu > delta), 1, 0)
#   cp = mean(ci$coverage)
#   cat("Coverage Probability (CP):", cp, "\n")
#   
#   metrics <- data.frame(delta = delta, bias_avg = bias_avg, bias_avg_median_ratio = bias_avg_median_ratio, sd_avg = sd_avg, sd_empirical = sd_empirical, cp = cp)
#   
#   cat("Metrics:\n")
#   print(metrics)
#   
#   return(metrics)
# }
# 



prior_params_list <- list(
  Yes = list(treatment.delta = log(0.85), control.delta = log(0.85), treatment.w = 0, control.w = NULL), # borrowing for the control arm
  No = list(treatment.delta = log(0.85), control.delta = log(0.85), treatment.w = 0, control.w = 0) # no borrowing
)

param_grid <- expand.grid(
  trt_n = c(seq(15,40,5), c(50, 100, 150, 200, 250, 300, 350, 400)), # Sample size for the treatment group.
  ctrl_n = c(seq(15,40,5), c(50, 100, 150, 200, 250, 300, 350, 400)), # Sample size for the control group.
  trt_prob = seq(0.05, 0.45, 0.1), # Probability of zero g-scores in the treatment group.
  ctrl_prob = seq(0, 0.4, 0.1), # Probability of zero g-scores in the control group.
  trt_mu = c(0.0018, 0.001), # Mean for the non-zero g-scores in the treatment group.
  ctrl_mu = 0.003, # Mean for the non-zero g-scores in the control group.
  trt_sigma = 1, # Standard deviation for the non-zero g-scores in the treatment group.
  ctrl_sigma = 1, # Standard deviation for the non-zero g-scores in the control group.
  ctrl_h_n = 200,
  ctrl_h_prob = seq(0, 0.4, 0.1),
  ctrl_h_mu = 0.003,
  ctrl_h_sigma = 1,
  stringsAsFactors = FALSE
) %>%
  filter(trt_n == ctrl_n, 
         trt_prob == ctrl_prob + 0.05,
         (trt_mu == 0.001 & ctrl_mu == 0.003) | 
           (trt_mu == 0.007 & ctrl_mu == 0.01),
         ctrl_h_prob == ctrl_prob)

data_gen_params_list <- lapply(apply(param_grid, 1, as.list),
                               create_data_gen_params, endpoint = "g-score")

## Run simulations
log_file <- "simulation_gscore_dist_log.txt"
sink(log_file, append = TRUE, split = FALSE)

nsim = 10000
all_results <- lapply(seq_along(data_gen_params_list), function(i) {
  data_gen_params <- data_gen_params_list[[i]]
  cat("Running", nsim, "simulations for data_gen_params set", i, "\n\n")
  for (arm in names(data_gen_params)) {
    cat("\t Arm:", arm, "\n")
    cat("\t  n:", data_gen_params[[arm]]$n, "\n")
    cat("\t  prob:", data_gen_params[[arm]]$prob, "\n")
    cat("\t  mu:", data_gen_params[[arm]]$mu, "\n")
    cat("\t  sigma:", data_gen_params[[arm]]$sigma, "\n\n")
  }
  t <- system.time({
    results <- run_simulation(endpoint = "g-score", nsim = nsim,
                              data_gen_params = data_gen_params, 
                              prior_params_list = prior_params_list,
                              posterior_infer = F)
  })
  cat("Elapsed time:", t["elapsed"], "seconds\n")
  cat("=======================================================\n\n")
  return(results)
})

while (sink.number() > 0) {
  sink(NULL)
}


combined_g_sd_intermediate <- do.call(rbind, lapply(seq_along(all_results), function(i) {
  res <- all_results[[i]]
  res$g_sd_intermediate$data_gen_setting <- i
  return(res$g_sd_intermediate)
}))

combined_median_est <- do.call(rbind, lapply(seq_along(all_results), function(i) {
  res <- all_results[[i]]
  res$median_est$data_gen_setting <- i
  return(res$median_est)
}))

combined_metrics_approx_dist <- do.call(rbind, lapply(seq_along(all_results), function(i) {
  res <- all_results[[i]]
  res$metrics_approx_dist$data_gen_setting <- i
  return(res$metrics_approx_dist)
}))

combined_metrics_post_dist <- do.call(rbind, lapply(seq_along(all_results), function(i) {
  res <- all_results[[i]]
  res$metrics_post_dist$data_gen_setting <- i
  return(res$metrics_post_dist)
}))

combined_post_params <- do.call(rbind, lapply(seq_along(all_results), function(i) {
  res <- all_results[[i]]
  res$post_params$data_gen_setting <- i
  return(res$post_params)
}))

combined_data <- do.call(rbind, lapply(seq_along(all_results), function(i) {
  res <- all_results[[i]]
  res$data$data_gen_setting <- i
  return(res$data)
}))

saveRDS(all_results, file = "sim_rslt_gscore_all_results_8_6.rds")
saveRDS(combined_median_est, file = "sim_rslt_gscore_median_est_8_6.rds")
saveRDS(combined_metrics_approx_dist, file = "sim_rslt_gscore_metrics_approx_dist_8_6.rds")
saveRDS(combined_metrics_post_dist, file = "sim_rslt_gscore_metrics_post_dist_8_6.rds")
saveRDS(combined_post_params, file = "sim_rslt_gscore_post_params_8_6.rds")



combined_metrics_post_dist <- readRDS("sim_rslt_gscore_metrics_post_dist_8_6.rds")

combined_metrics_post_dist$control.mu = round(exp(as.numeric(combined_metrics_post_dist$control.mu)), 3)
combined_metrics_post_dist$treatment.mu = round(exp(as.numeric(combined_metrics_post_dist$treatment.mu)), 4)
combined_metrics_post_dist$control_h.mu = round(exp(as.numeric(combined_metrics_post_dist$control_h.mu)), 3)
combined_metrics_post_dist$treatment.n = factor(combined_metrics_post_dist$treatment.n, levels = as.character(c(seq(15,40,5), c(50, 100, 150, 200, 250, 300, 350, 400))))
  
metrics_df <- combined_metrics_post_dist %>%
  select(treatment.mu, control.mu, control_h.mu, treatment.prob, control.prob, control_h.prob, true_value, treatment.n, borrowing,
         bias_avg_median_ratio1, sd_avg, sd_empirical, cp) %>%
  arrange(treatment.mu, control.mu, treatment.prob, treatment.n)

kbl(metrics_df, escape = F, row.names = F, 
    format    = "html", 
    longtable = T, 
    booktabs  = T, 
    col.names = c("Treatment", "Control", "Historical", "Treatment", "Control","Historical", "True Median Ratio\n(Treatment/Control)<sup>1</sup>", "Sample Size<sup>2</sup>", "Borrowing", "BIAS<sup>3</sup>", "SE<sup>4</sup>", "SD<sup>5</sup>", "CP<sup>6</sup>")) %>%
  kable_classic(full_width = FALSE) %>%
  add_header_above(c("Mean of positive g-score median" = 3, "Prob of Zero" = 3, " " = 7)) %>%
  collapse_rows(columns = 1:8, valign = "top") %>%
  footnote(number = c("True g-score median of treatment arm over true g-score median of control arm, obtained based on the zero-inflated lognormal distribution (determined by proportion of zeros in both arms)",
                      "Sample size for each arm.",
                      "Average bias of the estimated median ratio over 10K simulations.",
                      "Average standard error of the estimated log median ratio over 10K simulations.",
                      "Empirical standard deviation of the estimated log median ratio.",
                      "95% coverage probability under normal distribution."))


p1 <- ggplot(metrics_df, aes(x = treatment.n, y = bias_avg_median_ratio1, color = borrowing)) +
  geom_point() +
  facet_grid(~treatment.prob + control.prob, labeller = label_both) +
  geom_hline(yintercept = 0, color = "red", linetype = "dashed") +
  labs(x = "Sample Size", y = "Bias", title = "Average Bias") +
  theme_bw()

metrics_long <- metrics_df %>%
  pivot_longer(c(sd_avg, sd_empirical), names_to = "sd_type", values_to = "sd_value")

p2 <- ggplot(metrics_long, aes(x = treatment.n, y = sd_value, color = borrowing, shape = sd_type)) +
  geom_point() +
  facet_grid(~treatment.prob + control.prob, labeller = label_both) +
  labs(x = "Sample Size", y = "SD", title = "Average SD vs. Empirical SD") +
  theme_bw() +
  theme(legend.position = "bottom")

p3 <- ggplot(metrics_df, aes(x = treatment.n, color = borrowing, y = cp)) +
  geom_point() +
  facet_grid(~treatment.prob + control.prob, labeller = label_both) +
  geom_hline(yintercept = 0.95, color = "red", linetype = "dashed") +
  labs(x = "Sample Size", y = "Coverage probability", title = "Coverage Probability") +
  theme_bw()

p <- p1 / p2 / p3

ggsave(filename = "gscore_dist_check_post_metrics_8_6.jpg", p, width = 10, height = 16)


combined_metrics_post_dist <- readRDS("sim_rslt_gscore_metrics_post_dist_8_6.rds")
combined_metrics_approx_dist <- readRDS("sim_rslt_gscore_metrics_approx_dist_8_6.rds")

combined_metrics_post_dist <- combined_metrics_post_dist %>%
  mutate(across(
    .cols = -c(ends_with(".name"), "borrowing"),
    .fns = as.numeric
  ))

combined_metrics_approx_dist$borrowing <- "Frequentist"
combined_metrics_post_dist$borrowing <- ifelse(combined_metrics_post_dist$borrowing == "No", "Bayesian,\nNo Borrowing", "Bayesian,\nBorrowing")

combined_dist <- bind_rows(combined_metrics_approx_dist, combined_metrics_post_dist)

combined_dist$control.mu = round(exp(as.numeric(combined_dist$control.mu)), 3)
combined_dist$treatment.mu = round(exp(as.numeric(combined_dist$treatment.mu)), 4)
combined_dist$control_h.mu = round(exp(as.numeric(combined_dist$control_h.mu)), 3)
combined_dist$treatment.n = factor(combined_dist$treatment.n, levels = as.character(c(seq(15,40,5), c(50, 100, 150, 200, 250, 300, 350, 400))))
combined_dist$Approach <- combined_dist$borrowing

metrics_df <- combined_dist %>%
  select(treatment.mu, control.mu, control_h.mu, treatment.prob, control.prob, control_h.prob, true_value, treatment.n, Approach,
         bias_avg_median_ratio1, sd_avg, sd_empirical, cp) %>%
  arrange(treatment.mu, control.mu, treatment.prob, treatment.n)


kbl(metrics_df, escape = F, row.names = F, 
    format    = "html", 
    longtable = T, 
    booktabs  = T, 
    col.names = c("Treatment", "Control", "Historical", "Treatment", "Control","Historical", "True Median Ratio\n(Treatment/Control)<sup>1</sup>", "Sample Size<sup>2</sup>", "Approach", "BIAS<sup>3</sup>", "SE<sup>4</sup>", "SD<sup>5</sup>", "CP<sup>6</sup>")) %>%
  kable_classic(full_width = FALSE) %>%
  add_header_above(c("Mean of positive g-score median" = 3, "Prob of Zero" = 3, " " = 7)) %>%
  collapse_rows(columns = 1:8, valign = "top") %>%
  footnote(number = c("True g-score median of treatment arm over true g-score median of control arm, obtained based on the zero-inflated lognormal distribution (determined by proportion of zeros in both arms)",
                      "Sample size for each arm.",
                      "Average bias of the estimated median ratio over 10K simulations.",
                      "Average standard error of the estimated log median ratio over 10K simulations.",
                      "Empirical standard deviation of the estimated log median ratio.",
                      "95% coverage probability under normal distribution."))

metrics_df$probs <- paste0("Treatment Prob of Zero = ", metrics_df$treatment.prob, ", Control Prob of Zero = ", metrics_df$control.prob)
p1 <- ggplot(metrics_df, aes(x = treatment.n, y = bias_avg_median_ratio1, color = Approach)) +
  geom_point() +
  facet_grid(~probs) +
  geom_hline(yintercept = 0, color = "red", linetype = "dashed") +
  labs(x = "Sample Size", y = "Bias", title = "Average Bias") +
  theme_bw() +
  theme(legend.position = "bottom")


metrics_long <- metrics_df %>%
  pivot_longer(c(sd_avg, sd_empirical), names_to = "sd_type", values_to = "sd_value")

p2 <- ggplot(metrics_long, aes(x = treatment.n, y = sd_value, color = sd_type)) +
  geom_point() +
  facet_grid(Approach~probs) +
  labs(x = "Sample Size", y = "SD", title = "Average SD vs. Empirical SD") +
  theme_bw() +
  theme(legend.position = "bottom")

p3 <- ggplot(metrics_df, aes(x = treatment.n, color = Approach, y = cp)) +
  geom_point() +
  facet_grid(~probs) +
  geom_hline(yintercept = 0.95, color = "red", linetype = "dashed") +
  labs(x = "Sample Size", y = "Coverage probability", title = "Coverage Probability") +
  theme_bw() +
  theme(legend.position = "bottom")


p <- p1 / p2 / p3 + 
  plot_layout(heights = c(1,3,1))

ggsave(filename = "gscore_dist_check_post_metrics_8_6.jpg", p, width = 18, height = 10)

